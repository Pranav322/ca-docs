{"file_contents":{"app.py":{"content":"import streamlit as st\nimport os\nimport tempfile\nimport uuid\nfrom typing import Dict, Any, List, Optional\nimport logging\nimport time\n\n# Import our custom modules\nfrom database import VectorDatabase\nfrom pdf_processor import PDFProcessor\nfrom table_processor import TableProcessor\nfrom embeddings import EmbeddingManager\nfrom rag_pipeline import RAGPipeline\nfrom appwrite_client import AppwriteClient\nfrom utils import FileUtils, ValidationUtils, ProgressTracker, ResponseFormatter\nfrom config import CA_LEVELS, CA_PAPERS\nfrom curriculum_ui import CurriculumSelector, render_curriculum_filter\nfrom curriculum_manager import curriculum_manager\n\n# Configure logging\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n# Initialize session state\nif 'initialized' not in st.session_state:\n    st.session_state.initialized = False\n    st.session_state.processing_status = {}\n    st.session_state.uploaded_files = []\n    st.session_state.chat_history = []\n\ndef initialize_components():\n    \"\"\"Initialize all components\"\"\"\n    try:\n        if not st.session_state.initialized:\n            with st.spinner(\"Initializing CA RAG Assistant...\"):\n                st.session_state.vector_db = VectorDatabase()\n                st.session_state.pdf_processor = PDFProcessor()\n                st.session_state.table_processor = TableProcessor()\n                st.session_state.embedding_manager = EmbeddingManager()\n                st.session_state.rag_pipeline = RAGPipeline()\n                st.session_state.appwrite_client = AppwriteClient()\n                st.session_state.initialized = True\n                st.success(\"CA RAG Assistant initialized successfully!\")\n        return True\n    except Exception as e:\n        st.error(f\"Failed to initialize components: {str(e)}\")\n        logger.error(f\"Initialization failed: {e}\")\n        return False\n\ndef render_sidebar():\n    \"\"\"Render sidebar with navigation and filters\"\"\"\n    st.sidebar.title(\"ğŸ“ CA RAG Assistant\")\n    st.sidebar.markdown(\"---\")\n    \n    # Navigation\n    page = st.sidebar.selectbox(\n        \"Navigate to:\",\n        [\"ğŸ“š Ask Questions\", \"ğŸ“„ Upload Documents\", \"ğŸ“Š File Management\", \"â„¹ï¸ Help & Info\"]\n    )\n    \n    st.sidebar.markdown(\"---\")\n    \n    # Global filters (for question answering) - Now using curriculum selector\n    if page == \"ğŸ“š Ask Questions\":\n        st.sidebar.subheader(\"ğŸ¯ Filter by Syllabus\")\n        \n        # Use the new curriculum filter component\n        with st.sidebar:\n            filters = render_curriculum_filter(prefix=\"sidebar_filter\", title=\"\", show_clear=True)\n            \n            include_tables = st.checkbox(\"Include Tables\", value=True, key=\"include_tables\")\n    \n    return page\n\ndef render_file_upload():\n    \"\"\"Render file upload interface\"\"\"\n    st.header(\"ğŸ“„ Upload CA Study Materials\")\n    st.markdown(\"Upload PDF files from CA syllabus with proper metadata tagging\")\n    \n    # File upload\n    uploaded_file = st.file_uploader(\n        \"Choose PDF file\",\n        type=['pdf'],\n        help=\"Upload CA syllabus PDFs (Foundation, Intermediate, or Final level)\"\n    )\n    \n    if uploaded_file is not None:\n        # Display file info\n        st.success(f\"File selected: {uploaded_file.name} ({uploaded_file.size} bytes)\")\n        \n        # Smart Curriculum-based Metadata Tagging\n        st.subheader(\"ğŸ·ï¸ Smart Curriculum Tagging\")\n        st.markdown(\"Select the curriculum hierarchy to automatically tag your document\")\n        \n        # Initialize curriculum selector for upload\n        upload_selector = CurriculumSelector(prefix=\"upload\")\n        \n        # Render the curriculum selector\n        selection = upload_selector.render_complete_selector(\n            title=\"ğŸ“– Select Document Location in Curriculum\",\n            show_path=True,\n            columns=True\n        )\n        \n        # Show selection status\n        upload_selector.render_selection_status()\n        \n        # Additional metadata form\n        with st.form(\"metadata_form\"):\n            # Additional metadata\n            with st.expander(\"ğŸ“‹ Additional Information\"):\n                description = st.text_area(\"Description (optional)\", key=\"upload_description\")\n                tags = st.text_input(\"Tags (comma-separated)\", key=\"upload_tags\")\n            \n            submitted = st.form_submit_button(\"ğŸš€ Upload and Process\")\n            \n            if submitted:\n                if not upload_selector.is_complete_selection():\n                    missing = upload_selector.get_missing_selections()\n                    st.error(f\"Please complete the curriculum selection: {', '.join(missing)}\")\n                else:\n                    # Get the final selection from the curriculum selector\n                    final_selection = upload_selector.get_current_selection()\n                    \n                    process_uploaded_file(uploaded_file, {\n                        'level': final_selection['level'],\n                        'paper': final_selection['paper'],\n                        'module': final_selection['module'],\n                        'chapter': final_selection['chapter'],\n                        'unit': final_selection['unit'],\n                        'description': description or None,\n                        'tags': [tag.strip() for tag in tags.split(',') if tag.strip()] if tags else []\n                    })\n\ndef process_uploaded_file(uploaded_file, metadata: Dict[str, Any]):\n    \"\"\"Process uploaded PDF file\"\"\"\n    try:\n        # Generate unique file ID\n        file_id = FileUtils.generate_file_id(uploaded_file.name)\n        \n        # Add file name to metadata\n        metadata['file_name'] = uploaded_file.name\n        \n        # Validate metadata\n        validated_metadata = ValidationUtils.validate_metadata(metadata)\n        \n        # Create temporary file\n        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:\n            tmp_file.write(uploaded_file.getvalue())\n            tmp_file_path = tmp_file.name\n        \n        # Validate PDF\n        if not FileUtils.validate_pdf_file(tmp_file_path):\n            st.error(\"Invalid PDF file. Please upload a valid PDF.\")\n            FileUtils.cleanup_temp_file(tmp_file_path)\n            return\n        \n        # Initialize progress tracking\n        progress_bar = st.progress(0)\n        status_text = st.empty()\n        \n        # Step 1: Upload to Appwrite\n        status_text.text(\"ğŸ“¤ Uploading file to storage...\")\n        progress_bar.progress(10)\n        \n        appwrite_file_id = st.session_state.appwrite_client.upload_file(tmp_file_path, uploaded_file.name)\n        \n        # Step 2: Store metadata\n        status_text.text(\"ğŸ’¾ Storing file metadata...\")\n        progress_bar.progress(20)\n        \n        st.session_state.vector_db.store_file_metadata(\n            file_id=file_id,\n            file_name=uploaded_file.name,\n            appwrite_file_id=appwrite_file_id,\n            level=validated_metadata['level'],\n            paper=validated_metadata['paper'],\n            module=validated_metadata.get('module'),\n            chapter=validated_metadata.get('chapter'),\n            unit=validated_metadata.get('unit')\n        )\n        \n        # Step 3: Process PDF content\n        status_text.text(\"ğŸ” Extracting text and tables...\")\n        progress_bar.progress(30)\n        \n        pdf_results = st.session_state.pdf_processor.extract_text_and_tables(tmp_file_path)\n        \n        # Step 4: Update page count\n        total_pages = pdf_results['metadata']['total_pages']\n        st.session_state.vector_db.store_file_metadata(\n            file_id=file_id,\n            file_name=uploaded_file.name,\n            appwrite_file_id=appwrite_file_id,\n            level=validated_metadata['level'],\n            paper=validated_metadata['paper'],\n            module=validated_metadata.get('module'),\n            chapter=validated_metadata.get('chapter'),\n            unit=validated_metadata.get('unit'),\n            total_pages=total_pages\n        )\n        \n        # Step 5: Process text chunks\n        if pdf_results['text_chunks']:\n            status_text.text(\"âœ‚ï¸ Processing text chunks...\")\n            progress_bar.progress(50)\n            \n            # Create table-aware chunks\n            tables_info = [{'extraction_method': t.get('extraction_method', ''), 'rows': t.get('rows', 0)} \n                          for t in pdf_results['tables']]\n            \n            processed_chunks = []\n            for chunk_data in pdf_results['text_chunks']:\n                chunk_content = chunk_data['content']\n                table_aware_chunks = st.session_state.table_processor.chunk_table_aware_text(\n                    chunk_content, tables_info, chunk_size=1000, overlap=200\n                )\n                processed_chunks.extend(table_aware_chunks)\n            \n            # Step 6: Generate embeddings for chunks\n            status_text.text(\"ğŸ§  Generating embeddings for text...\")\n            progress_bar.progress(70)\n            \n            chunk_embeddings = st.session_state.embedding_manager.process_document_chunks(\n                processed_chunks, validated_metadata\n            )\n            \n            # Step 7: Store chunks in database\n            status_text.text(\"ğŸ’¾ Storing text chunks...\")\n            progress_bar.progress(80)\n            \n            for i, chunk in enumerate(chunk_embeddings):\n                st.session_state.vector_db.store_document_chunk(\n                    file_id=file_id,\n                    file_name=uploaded_file.name,\n                    content=chunk['content'],\n                    embedding=chunk['embedding'],\n                    metadata=chunk['metadata'],\n                    chunk_index=i,\n                    level=validated_metadata['level'],\n                    paper=validated_metadata['paper'],\n                    module=validated_metadata.get('module'),\n                    chapter=validated_metadata.get('chapter'),\n                    unit=validated_metadata.get('unit')\n                )\n        \n        # Step 8: Process tables\n        if pdf_results['tables']:\n            status_text.text(\"ğŸ“Š Processing tables...\")\n            progress_bar.progress(85)\n            \n            table_embeddings = st.session_state.embedding_manager.process_tables(\n                pdf_results['tables'], validated_metadata\n            )\n            \n            # Store tables in database\n            for i, table in enumerate(table_embeddings):\n                st.session_state.vector_db.store_table(\n                    file_id=file_id,\n                    file_name=uploaded_file.name,\n                    table_data=table['data'] if 'data' in table else {},\n                    table_html=table.get('html', ''),\n                    embedding=table['embedding'],\n                    context_before=table.get('context_before', ''),\n                    context_after=table.get('context_after', ''),\n                    page_number=table.get('page_number', 0),\n                    table_index=i,\n                    level=validated_metadata['level'],\n                    paper=validated_metadata['paper'],\n                    module=validated_metadata.get('module'),\n                    chapter=validated_metadata.get('chapter'),\n                    unit=validated_metadata.get('unit')\n                )\n        \n        # Step 9: Update processing status\n        status_text.text(\"âœ… Finalizing...\")\n        progress_bar.progress(95)\n        \n        st.session_state.vector_db.update_processing_status(file_id, \"completed\")\n        \n        progress_bar.progress(100)\n        status_text.text(\"ğŸ‰ Processing completed successfully!\")\n        \n        # Cleanup\n        FileUtils.cleanup_temp_file(tmp_file_path)\n        \n        # Show summary\n        st.success(f\"\"\"\n        **File processed successfully!**\n        - **File:** {uploaded_file.name}\n        - **Level:** {validated_metadata['level']}\n        - **Paper:** {validated_metadata['paper']}\n        - **Total Pages:** {total_pages}\n        - **Text Chunks:** {len(pdf_results['text_chunks'])}\n        - **Tables Found:** {len(pdf_results['tables'])}\n        \"\"\")\n        \n        # Add to session state\n        st.session_state.uploaded_files.append({\n            'file_id': file_id,\n            'file_name': uploaded_file.name,\n            'metadata': validated_metadata,\n            'status': 'completed',\n            'upload_time': time.time()\n        })\n        \n    except Exception as e:\n        st.error(f\"Error processing file: {str(e)}\")\n        logger.error(f\"File processing error: {e}\")\n        \n        # Cleanup on error\n        try:\n            if 'tmp_file_path' in locals():\n                FileUtils.cleanup_temp_file(tmp_file_path)\n        except:\n            pass\n\ndef render_question_interface():\n    \"\"\"Render question answering interface\"\"\"\n    st.header(\"ğŸ“š Ask Questions about CA Syllabus\")\n    st.markdown(\"Ask any question about Chartered Accountancy topics and get comprehensive answers with references.\")\n    \n    # Question input\n    question = st.text_area(\n        \"Enter your question:\",\n        placeholder=\"e.g., What are the key components of a balance sheet as per Schedule III of Companies Act 2013?\",\n        height=100,\n        help=\"Be specific for better results. You can ask about concepts, procedures, standards, or calculations.\"\n    )\n    \n    # Question options\n    col1, col2 = st.columns([3, 1])\n    \n    with col2:\n        ask_button = st.button(\"ğŸš€ Get Answer\", type=\"primary\")\n        clear_button = st.button(\"ğŸ—‘ï¸ Clear History\")\n    \n    if clear_button:\n        st.session_state.chat_history = []\n        st.rerun()\n    \n    if ask_button:\n        if not question.strip():\n            st.error(\"Please enter a question.\")\n            return\n        \n        if not ValidationUtils.validate_question(question):\n            st.error(\"Please enter a valid question (5-1000 characters).\")\n            return\n        \n        # Get filters from the new curriculum selector in sidebar\n        level_filter = st.session_state.get('sidebar_filter_level')\n        paper_filter = st.session_state.get('sidebar_filter_paper')\n        module_filter = st.session_state.get('sidebar_filter_module')\n        chapter_filter = st.session_state.get('sidebar_filter_chapter')\n        unit_filter = st.session_state.get('sidebar_filter_unit')\n        include_tables = st.session_state.get('include_tables', True)\n        \n        # Show processing\n        with st.spinner(\"ğŸ” Searching knowledge base and generating answer...\"):\n            try:\n                # Get answer from RAG pipeline\n                answer_data = st.session_state.rag_pipeline.answer_question(\n                    question=question,\n                    level=level_filter,\n                    paper=paper_filter,\n                    module=module_filter,\n                    chapter=chapter_filter,\n                    unit=unit_filter,\n                    include_tables=include_tables\n                )\n                \n                # Add to chat history\n                st.session_state.chat_history.append({\n                    'question': question,\n                    'answer_data': answer_data,\n                    'timestamp': time.time(),\n                    'filters': {\n                        'level': level_filter,\n                        'paper': paper_filter,\n                        'module': module_filter,\n                        'chapter': chapter_filter,\n                        'unit': unit_filter\n                    }\n                })\n                \n            except Exception as e:\n                st.error(f\"Error generating answer: {str(e)}\")\n                logger.error(f\"Question answering error: {e}\")\n    \n    # Display chat history\n    if st.session_state.chat_history:\n        st.markdown(\"---\")\n        st.subheader(\"ğŸ’¬ Q&A History\")\n        \n        # Reverse to show latest first\n        for i, chat in enumerate(reversed(st.session_state.chat_history)):\n            with st.expander(f\"Q: {chat['question'][:100]}{'...' if len(chat['question']) > 100 else ''}\", expanded=(i==0)):\n                render_answer_display(chat['answer_data'], chat['question'])\n                \n                # Show applied filters with curriculum hierarchy\n                if any(chat['filters'].values()):\n                    st.markdown(\"**ğŸ¯ Applied Filters:**\")\n                    # Create display path from hierarchy\n                    path_parts = []\n                    if chat['filters']['level']:\n                        path_parts.append(chat['filters']['level'])\n                    if chat['filters']['paper']:\n                        path_parts.append(chat['filters']['paper'])\n                    if chat['filters']['module']:\n                        path_parts.append(chat['filters']['module'])\n                    if chat['filters']['chapter']:\n                        path_parts.append(chat['filters']['chapter'])\n                    if chat['filters']['unit']:\n                        path_parts.append(chat['filters']['unit'])\n                    \n                    if path_parts:\n                        filter_path = \" â†’ \".join(path_parts)\n                        st.caption(f\"ğŸ“ {filter_path}\")\n                else:\n                    st.caption(\"ğŸŒ No filters applied - searched across all content\")\n    else:\n        st.info(\"ğŸ‘‹ Ask your first question to get started! Use the filters in the sidebar to narrow down your search.\")\n\ndef render_answer_display(answer_data: Dict[str, Any], question: str):\n    \"\"\"Render answer with sources and metadata\"\"\"\n    \n    # Main answer\n    st.markdown(\"**ğŸ“ Answer:**\")\n    st.markdown(answer_data['answer'])\n    \n    # Confidence and metadata\n    col1, col2, col3 = st.columns(3)\n    \n    with col1:\n        confidence = answer_data.get('confidence', 0)\n        st.metric(\"Confidence\", f\"{confidence*100:.1f}%\")\n    \n    with col2:\n        docs_found = answer_data['metadata'].get('documents_found', 0)\n        st.metric(\"Documents\", docs_found)\n    \n    with col3:\n        tables_found = answer_data['metadata'].get('tables_found', 0)\n        st.metric(\"Tables\", tables_found)\n    \n    # Sources\n    sources = answer_data.get('sources', {})\n    \n    if sources.get('documents') or sources.get('tables'):\n        st.markdown(\"**ğŸ“š Sources:**\")\n        \n        # Document sources\n        if sources.get('documents'):\n            with st.expander(f\"ğŸ“„ Document Sources ({len(sources['documents'])})\"):\n                for i, doc in enumerate(sources['documents']):\n                    st.markdown(f\"\"\"\n                    **{i+1}. {doc['file_name']}**\n                    - Level: {doc['level']}, Paper: {doc['paper']}\n                    - Chapter: {doc.get('chapter', 'N/A')}\n                    - Similarity: {doc['similarity']:.2f}\n                    - Snippet: {doc['snippet']}\n                    \"\"\")\n        \n        # Table sources\n        if sources.get('tables'):\n            with st.expander(f\"ğŸ“Š Table Sources ({len(sources['tables'])})\"):\n                for i, table in enumerate(sources['tables']):\n                    st.markdown(f\"\"\"\n                    **{i+1}. {table['file_name']} (Page {table['page_number']})**\n                    - Level: {table['level']}, Paper: {table['paper']}\n                    - Dimensions: {table['rows']} rows Ã— {table['cols']} columns\n                    - Similarity: {table['similarity']:.2f}\n                    - Context: {table.get('context', 'N/A')}\n                    \"\"\")\n    \n    # Suggestions\n    if answer_data.get('suggestions'):\n        st.markdown(\"**ğŸ’¡ Related Questions:**\")\n        for i, suggestion in enumerate(answer_data['suggestions']):\n            if st.button(suggestion, key=f\"suggest_{i}_{hash(suggestion)}_{hash(question)}\"):\n                st.session_state.suggested_question = suggestion\n                st.rerun()\n\ndef render_file_management():\n    \"\"\"Render file management interface\"\"\"\n    st.header(\"ğŸ“Š File Management\")\n    st.markdown(\"Manage uploaded files and monitor processing status\")\n    \n    try:\n        # Get file metadata from database\n        all_files = st.session_state.vector_db.get_file_metadata()\n        \n        if not all_files:\n            st.info(\"No files uploaded yet. Go to the Upload Documents page to get started.\")\n            return\n        \n        # File statistics\n        st.subheader(\"ğŸ“ˆ Overview\")\n        \n        col1, col2, col3, col4 = st.columns(4)\n        \n        with col1:\n            st.metric(\"Total Files\", len(all_files))\n        \n        with col2:\n            completed_files = len([f for f in all_files if f.get('processing_status') == 'completed'])\n            st.metric(\"Processed\", completed_files)\n        \n        with col3:\n            pending_files = len([f for f in all_files if f.get('processing_status') == 'pending'])\n            st.metric(\"Pending\", pending_files)\n        \n        with col4:\n            total_pages = sum(f.get('total_pages', 0) for f in all_files)\n            st.metric(\"Total Pages\", total_pages)\n        \n        # File list\n        st.subheader(\"ğŸ“‹ File List\")\n        \n        # Filter options\n        col1, col2, col3 = st.columns(3)\n        \n        with col1:\n            level_filter = st.selectbox(\"Filter by Level\", [\"All\"] + CA_LEVELS, key=\"mgmt_level_filter\")\n        \n        with col2:\n            status_filter = st.selectbox(\"Filter by Status\", [\"All\", \"completed\", \"pending\", \"error\"], key=\"mgmt_status_filter\")\n        \n        with col3:\n            search_term = st.text_input(\"Search files\", placeholder=\"Enter file name...\", key=\"mgmt_search\")\n        \n        # Apply filters\n        filtered_files = all_files\n        \n        if level_filter != \"All\":\n            filtered_files = [f for f in filtered_files if f.get('level') == level_filter]\n        \n        if status_filter != \"All\":\n            filtered_files = [f for f in filtered_files if f.get('processing_status') == status_filter]\n        \n        if search_term:\n            filtered_files = [f for f in filtered_files if search_term.lower() in f.get('file_name', '').lower()]\n        \n        # Display files\n        for file_data in filtered_files:\n            with st.expander(f\"ğŸ“„ {file_data.get('file_name', 'Unknown')} - {file_data.get('processing_status', 'Unknown').title()}\"):\n                \n                col1, col2 = st.columns(2)\n                \n                with col1:\n                    st.markdown(f\"\"\"\n                    **File Details:**\n                    - **Level:** {file_data.get('level', 'N/A')}\n                    - **Paper:** {file_data.get('paper', 'N/A')}\n                    - **Module:** {file_data.get('module', 'N/A') or 'N/A'}\n                    - **Chapter:** {file_data.get('chapter', 'N/A') or 'N/A'}\n                    \"\"\")\n                \n                with col2:\n                    st.markdown(f\"\"\"\n                    **Processing Info:**\n                    - **Status:** {file_data.get('processing_status', 'Unknown')}\n                    - **Total Pages:** {file_data.get('total_pages', 0)}\n                    - **Upload Date:** {file_data.get('upload_date', 'Unknown')}\n                    - **File ID:** {file_data.get('file_id', 'Unknown')[:20]}...\n                    \"\"\")\n                \n                # Action buttons\n                col1, col2, col3 = st.columns(3)\n                \n                with col1:\n                    if st.button(\"ğŸ”„ Reprocess\", key=f\"reprocess_{file_data.get('id')}\"):\n                        st.info(\"Reprocessing functionality would be implemented here\")\n                \n                with col2:\n                    if st.button(\"ğŸ“Š View Stats\", key=f\"stats_{file_data.get('id')}\"):\n                        show_file_statistics(file_data)\n                \n                with col3:\n                    if st.button(\"ğŸ—‘ï¸ Delete\", key=f\"delete_{file_data.get('id')}\"):\n                        st.warning(\"Delete functionality would be implemented with confirmation\")\n    \n    except Exception as e:\n        st.error(f\"Error loading file management data: {str(e)}\")\n        logger.error(f\"File management error: {e}\")\n\ndef show_file_statistics(file_data: Dict[str, Any]):\n    \"\"\"Show detailed statistics for a file\"\"\"\n    st.markdown(\"---\")\n    st.markdown(f\"**ğŸ“Š Detailed Statistics for {file_data.get('file_name')}**\")\n    \n    try:\n        # This would query the database for chunk and table counts\n        # For now, showing placeholder structure\n        st.info(\"Detailed statistics would show:\")\n        st.markdown(\"\"\"\n        - Number of text chunks extracted\n        - Number of tables found\n        - Processing methods used\n        - Embedding generation statistics  \n        - Error logs (if any)\n        \"\"\")\n    except Exception as e:\n        st.error(f\"Error loading statistics: {str(e)}\")\n\ndef render_help_info():\n    \"\"\"Render help and information page\"\"\"\n    st.header(\"â„¹ï¸ Help & Information\")\n    \n    tab1, tab2, tab3, tab4 = st.tabs([\"ğŸ“– How to Use\", \"ğŸ”§ Features\", \"â“ FAQ\", \"ğŸ“ Support\"])\n    \n    with tab1:\n        st.markdown(\"\"\"\n        ## ğŸš€ Getting Started\n        \n        ### 1. Upload Documents\n        - Go to **Upload Documents** page\n        - Select a CA syllabus PDF file\n        - Fill in the metadata (Level, Paper, Module, Chapter, Unit)\n        - Click **Upload and Process**\n        \n        ### 2. Ask Questions\n        - Go to **Ask Questions** page\n        - Use sidebar filters to narrow down your search\n        - Type your question in natural language\n        - Get comprehensive answers with sources\n        \n        ### 3. Manage Files\n        - View all uploaded files in **File Management**\n        - Monitor processing status\n        - Filter and search through files\n        \"\"\")\n    \n    with tab2:\n        st.markdown(\"\"\"\n        ## âœ¨ Key Features\n        \n        ### ğŸ“Š Table-Aware Processing\n        - Advanced table extraction from PDFs\n        - Preserves financial data structure\n        - Maintains numerical relationships\n        \n        ### ğŸ§  Smart Embeddings\n        - Azure OpenAI embeddings\n        - Context-aware processing\n        - Metadata-enhanced search\n        \n        ### ğŸ¯ Hierarchical Filtering\n        - Filter by CA Level (Foundation/Intermediate/Final)\n        - Narrow down by Paper, Module, Chapter, Unit\n        - Progressive difficulty recommendations\n        \n        ### ğŸ“š Comprehensive Sources\n        - Document chunks with similarity scores\n        - Table references with context\n        - Precise citations and references\n        \n        ### ğŸ’¡ Learning Assistance\n        - Related question suggestions\n        - Progressive learning paths\n        - Context-aware responses\n        \"\"\")\n    \n    with tab3:\n        st.markdown(\"\"\"\n        ## â“ Frequently Asked Questions\n        \n        ### Q: What file formats are supported?\n        A: Currently only PDF files are supported.\n        \n        ### Q: How long does processing take?\n        A: Processing time depends on file size and complexity. Typically 1-5 minutes per file.\n        \n        ### Q: Can I upload scanned PDFs?\n        A: Yes, the system includes OCR capabilities for scanned documents.\n        \n        ### Q: How accurate are the answers?\n        A: Answers include confidence scores. Higher confidence indicates better matches.\n        \n        ### Q: Can I search within specific chapters?\n        A: Yes, use the sidebar filters to narrow down to specific modules, chapters, or units.\n        \n        ### Q: What if my question doesn't get good results?\n        A: Try rephrasing your question, use more specific terms, or check if relevant documents are uploaded.\n        \"\"\")\n    \n    with tab4:\n        st.markdown(\"\"\"\n        ## ğŸ“ Support & Technical Info\n        \n        ### ğŸ—ï¸ Architecture\n        - **Frontend**: Streamlit web application\n        - **Backend**: Python with FastAPI\n        - **Database**: PostgreSQL with pgvector\n        - **Storage**: Appwrite for file management\n        - **AI**: Azure OpenAI for embeddings and LLM\n        \n        ### ğŸ”§ Processing Pipeline\n        1. PDF upload and metadata tagging\n        2. Multi-method content extraction (PyMuPDF, pdfplumber, camelot, tabula)\n        3. Table-aware text chunking\n        4. Embedding generation with Azure OpenAI\n        5. Vector storage in pgvector database\n        6. RAG-based question answering\n        \n        ### ğŸ“Š Supported Content Types\n        - Text content from PDFs\n        - Financial tables and schedules\n        - Scanned documents (with OCR)\n        - Multi-column layouts\n        - Charts and diagrams (text extraction)\n        \n        ### ğŸ›¡ï¸ Data Security\n        - Files stored securely in Appwrite\n        - Metadata organized hierarchically\n        - Processing logs maintained\n        - No data sharing with external parties\n        \"\"\")\n\ndef main():\n    \"\"\"Main application entry point\"\"\"\n    st.set_page_config(\n        page_title=\"CA RAG Assistant\",\n        page_icon=\"ğŸ“\",\n        layout=\"wide\",\n        initial_sidebar_state=\"expanded\"\n    )\n    \n    # Initialize components\n    if not initialize_components():\n        st.stop()\n    \n    # Render sidebar and get current page\n    current_page = render_sidebar()\n    \n    # Handle suggested question\n    if 'suggested_question' in st.session_state:\n        # Auto-fill the question and switch to questions page\n        if current_page == \"ğŸ“š Ask Questions\":\n            # The question will be auto-filled in the interface\n            pass\n        del st.session_state.suggested_question\n    \n    # Route to appropriate page\n    if current_page == \"ğŸ“š Ask Questions\":\n        render_question_interface()\n    elif current_page == \"ğŸ“„ Upload Documents\":\n        render_file_upload()\n    elif current_page == \"ğŸ“Š File Management\":\n        render_file_management()\n    elif current_page == \"â„¹ï¸ Help & Info\":\n        render_help_info()\n    \n    # Footer\n    st.markdown(\"---\")\n    st.markdown(\n        \"<div style='text-align: center; color: gray;'>\"\n        \"ğŸ“ CA RAG Assistant - Empowering Chartered Accountancy Students with AI\"\n        \"</div>\",\n        unsafe_allow_html=True\n    )\n\nif __name__ == \"__main__\":\n    main()\n","size_bytes":30376},"appwrite_client.py":{"content":"from appwrite.client import Client\nfrom appwrite.services.storage import Storage\nfrom appwrite.services.databases import Databases\nfrom appwrite.services.account import Account\nfrom appwrite.input_file import InputFile\nfrom appwrite.id import ID\nimport os\nimport logging\nfrom typing import Dict, Any, Optional, List\nfrom config import APPWRITE_ENDPOINT, APPWRITE_PROJECT_ID, APPWRITE_API_KEY, APPWRITE_BUCKET_ID\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nclass AppwriteClient:\n    def __init__(self):\n        self.client = Client()\n        self.client.set_endpoint(APPWRITE_ENDPOINT)\n        self.client.set_project(APPWRITE_PROJECT_ID)\n        self.client.set_key(APPWRITE_API_KEY)\n        \n        self.storage = Storage(self.client)\n        self.databases = Databases(self.client)\n        \n        self.bucket_id = APPWRITE_BUCKET_ID\n        self.database_id = \"ca_rag_metadata\"\n        self.collection_id = \"file_metadata\"\n        \n        self._ensure_setup()\n    \n    def _ensure_setup(self):\n        \"\"\"Ensure database and collections are set up\"\"\"\n        try:\n            # Try to get database, create if doesn't exist\n            try:\n                self.databases.get(self.database_id)\n            except Exception:\n                logger.info(\"Creating Appwrite database...\")\n                self.databases.create(\n                    database_id=self.database_id,\n                    name=\"CA RAG Metadata Database\"\n                )\n            \n            # Try to get collection, create if doesn't exist\n            try:\n                self.databases.get_collection(self.database_id, self.collection_id)\n            except Exception:\n                logger.info(\"Creating Appwrite collection...\")\n                self.databases.create_collection(\n                    database_id=self.database_id,\n                    collection_id=self.collection_id,\n                    name=\"File Metadata Collection\"\n                )\n                \n                # Create attributes for the collection\n                attributes = [\n                    {\"key\": \"file_id\", \"type\": \"string\", \"size\": 255, \"required\": True},\n                    {\"key\": \"file_name\", \"type\": \"string\", \"size\": 500, \"required\": True},\n                    {\"key\": \"level\", \"type\": \"string\", \"size\": 100, \"required\": True},\n                    {\"key\": \"paper\", \"type\": \"string\", \"size\": 200, \"required\": True},\n                    {\"key\": \"module\", \"type\": \"string\", \"size\": 200, \"required\": False},\n                    {\"key\": \"chapter\", \"type\": \"string\", \"size\": 200, \"required\": False},\n                    {\"key\": \"unit\", \"type\": \"string\", \"size\": 200, \"required\": False},\n                    {\"key\": \"total_pages\", \"type\": \"integer\", \"required\": False},\n                    {\"key\": \"processing_status\", \"type\": \"string\", \"size\": 50, \"required\": False},\n                ]\n                \n                for attr in attributes:\n                    if attr[\"type\"] == \"string\":\n                        self.databases.create_string_attribute(\n                            database_id=self.database_id,\n                            collection_id=self.collection_id,\n                            key=attr[\"key\"],\n                            size=attr[\"size\"],\n                            required=attr[\"required\"]\n                        )\n                    elif attr[\"type\"] == \"integer\":\n                        self.databases.create_integer_attribute(\n                            database_id=self.database_id,\n                            collection_id=self.collection_id,\n                            key=attr[\"key\"],\n                            required=attr[\"required\"]\n                        )\n            \n        except Exception as e:\n            logger.warning(f\"Appwrite setup warning: {e}\")\n    \n    def upload_file(self, file_path: str, file_name: str) -> str:\n        \"\"\"Upload a PDF file to Appwrite storage\"\"\"\n        try:\n            # Create file input\n            with open(file_path, 'rb') as file:\n                file_input = InputFile.from_bytes(\n                    file.read(),\n                    filename=file_name\n                )\n            \n            # Upload file\n            result = self.storage.create_file(\n                bucket_id=self.bucket_id,\n                file_id=ID.unique(),\n                file=file_input\n            )\n            \n            logger.info(f\"File uploaded successfully: {result['$id']}\")\n            return result['$id']\n            \n        except Exception as e:\n            logger.error(f\"Failed to upload file: {e}\")\n            raise\n    \n    def store_file_metadata(self, file_id: str, metadata: Dict[str, Any]) -> str:\n        \"\"\"Store file metadata in Appwrite database\"\"\"\n        try:\n            # Prepare document data\n            document_data = {\n                \"file_id\": file_id,\n                \"file_name\": metadata.get(\"file_name\", \"\"),\n                \"level\": metadata.get(\"level\", \"\"),\n                \"paper\": metadata.get(\"paper\", \"\"),\n                \"module\": metadata.get(\"module\", \"\"),\n                \"chapter\": metadata.get(\"chapter\", \"\"),\n                \"unit\": metadata.get(\"unit\", \"\"),\n                \"total_pages\": metadata.get(\"total_pages\", 0),\n                \"processing_status\": metadata.get(\"processing_status\", \"pending\")\n            }\n            \n            # Create document\n            result = self.databases.create_document(\n                database_id=self.database_id,\n                collection_id=self.collection_id,\n                document_id=ID.unique(),\n                data=document_data\n            )\n            \n            logger.info(f\"Metadata stored successfully: {result['$id']}\")\n            return result['$id']\n            \n        except Exception as e:\n            logger.error(f\"Failed to store metadata: {e}\")\n            raise\n    \n    def get_file_metadata(self, file_id: str = None) -> List[Dict[str, Any]]:\n        \"\"\"Retrieve file metadata from Appwrite\"\"\"\n        try:\n            if file_id:\n                # Get specific file metadata\n                results = self.databases.list_documents(\n                    database_id=self.database_id,\n                    collection_id=self.collection_id,\n                    queries=[f'equal(\"file_id\", \"{file_id}\")']\n                )\n            else:\n                # Get all file metadata\n                results = self.databases.list_documents(\n                    database_id=self.database_id,\n                    collection_id=self.collection_id\n                )\n            \n            return [doc for doc in results['documents']]\n            \n        except Exception as e:\n            logger.error(f\"Failed to retrieve metadata: {e}\")\n            return []\n    \n    def update_processing_status(self, file_id: str, status: str) -> bool:\n        \"\"\"Update file processing status\"\"\"\n        try:\n            # First find the document\n            results = self.databases.list_documents(\n                database_id=self.database_id,\n                collection_id=self.collection_id,\n                queries=[f'equal(\"file_id\", \"{file_id}\")']\n            )\n            \n            if not results['documents']:\n                logger.error(f\"No document found for file_id: {file_id}\")\n                return False\n            \n            document_id = results['documents'][0]['$id']\n            \n            # Update the document\n            self.databases.update_document(\n                database_id=self.database_id,\n                collection_id=self.collection_id,\n                document_id=document_id,\n                data={\"processing_status\": status}\n            )\n            \n            logger.info(f\"Processing status updated to {status} for file {file_id}\")\n            return True\n            \n        except Exception as e:\n            logger.error(f\"Failed to update processing status: {e}\")\n            return False\n    \n    def download_file(self, file_id: str, local_path: str) -> bool:\n        \"\"\"Download a file from Appwrite storage\"\"\"\n        try:\n            # Get file download\n            file_data = self.storage.get_file_download(\n                bucket_id=self.bucket_id,\n                file_id=file_id\n            )\n            \n            # Save to local path\n            with open(local_path, 'wb') as file:\n                file.write(file_data)\n            \n            logger.info(f\"File downloaded successfully to {local_path}\")\n            return True\n            \n        except Exception as e:\n            logger.error(f\"Failed to download file: {e}\")\n            return False\n    \n    def delete_file(self, file_id: str) -> bool:\n        \"\"\"Delete a file from Appwrite storage\"\"\"\n        try:\n            self.storage.delete_file(\n                bucket_id=self.bucket_id,\n                file_id=file_id\n            )\n            \n            logger.info(f\"File deleted successfully: {file_id}\")\n            return True\n            \n        except Exception as e:\n            logger.error(f\"Failed to delete file: {e}\")\n            return False\n    \n    def store_extracted_data(self, file_id: str, extracted_data: Dict[str, Any]) -> str:\n        \"\"\"Store extracted table and text data\"\"\"\n        try:\n            # Create a separate collection for extracted data if needed\n            collection_id = \"extracted_data\"\n            \n            try:\n                self.databases.get_collection(self.database_id, collection_id)\n            except Exception:\n                # Create collection for extracted data\n                self.databases.create_collection(\n                    database_id=self.database_id,\n                    collection_id=collection_id,\n                    name=\"Extracted Data Collection\"\n                )\n                \n                # Create attributes\n                self.databases.create_string_attribute(\n                    database_id=self.database_id,\n                    collection_id=collection_id,\n                    key=\"file_id\",\n                    size=255,\n                    required=True\n                )\n                self.databases.create_string_attribute(\n                    database_id=self.database_id,\n                    collection_id=collection_id,\n                    key=\"data_type\",\n                    size=50,\n                    required=True\n                )\n                self.databases.create_string_attribute(\n                    database_id=self.database_id,\n                    collection_id=collection_id,\n                    key=\"content\",\n                    size=10000,\n                    required=True\n                )\n            \n            # Store the extracted data\n            result = self.databases.create_document(\n                database_id=self.database_id,\n                collection_id=collection_id,\n                document_id=ID.unique(),\n                data={\n                    \"file_id\": file_id,\n                    \"data_type\": extracted_data.get(\"type\", \"unknown\"),\n                    \"content\": str(extracted_data)[:10000]  # Truncate if too long\n                }\n            )\n            \n            logger.info(f\"Extracted data stored successfully: {result['$id']}\")\n            return result['$id']\n            \n        except Exception as e:\n            logger.error(f\"Failed to store extracted data: {e}\")\n            raise\n    \n    def get_storage_usage(self) -> Dict[str, Any]:\n        \"\"\"Get storage usage statistics\"\"\"\n        try:\n            # List all files in bucket\n            files = self.storage.list_files(bucket_id=self.bucket_id)\n            \n            total_size = sum(file.get('sizeOriginal', 0) for file in files['files'])\n            \n            return {\n                'total_files': files['total'],\n                'total_size_bytes': total_size,\n                'total_size_mb': round(total_size / (1024 * 1024), 2)\n            }\n            \n        except Exception as e:\n            logger.error(f\"Failed to get storage usage: {e}\")\n            return {'total_files': 0, 'total_size_bytes': 0, 'total_size_mb': 0}\n","size_bytes":12134},"config.py":{"content":"import os\n\n# Azure OpenAI Configuration\nAZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\", \"\")\nAZURE_OPENAI_KEY = os.getenv(\"AZURE_OPENAI_KEY\", \"\")\nAZURE_OPENAI_VERSION = os.getenv(\"AZURE_OPENAI_VERSION\", \"2024-02-01\")\nAZURE_EMBEDDINGS_DEPLOYMENT = os.getenv(\"AZURE_EMBEDDINGS_DEPLOYMENT\", \"text-embedding-ada-002\")\nAZURE_LLM_DEPLOYMENT = os.getenv(\"AZURE_LLM_DEPLOYMENT\", \"gpt-4\")\n\n# Database Configuration\nDATABASE_URL = os.getenv(\"DATABASE_URL\", \"postgresql://user:password@localhost:5432/ca_rag_db\")\nPGHOST = os.getenv(\"PGHOST\", \"localhost\")\nPGPORT = os.getenv(\"PGPORT\", \"5432\")\nPGDATABASE = os.getenv(\"PGDATABASE\", \"ca_rag_db\")\nPGUSER = os.getenv(\"PGUSER\", \"user\")\nPGPASSWORD = os.getenv(\"PGPASSWORD\", \"password\")\n\n# Appwrite Configuration\nAPPWRITE_ENDPOINT = os.getenv(\"APPWRITE_ENDPOINT\", \"\")\nAPPWRITE_PROJECT_ID = os.getenv(\"APPWRITE_PROJECT_ID\", \"\")\nAPPWRITE_API_KEY = os.getenv(\"APPWRITE_API_KEY\", \"\")\nAPPWRITE_BUCKET_ID = os.getenv(\"APPWRITE_BUCKET_ID\", \"ca-pdfs\")\n\n# Chunking Configuration\nCHUNK_SIZE = 1000\nCHUNK_OVERLAP = 200\nTABLE_CONTEXT_SIZE = 500\n\n# CA Course Structure\nCA_LEVELS = [\"Foundation\", \"Intermediate\", \"Final\"]\nCA_PAPERS = {\n    \"Foundation\": [\"Paper 1\", \"Paper 2\", \"Paper 3\", \"Paper 4\"],\n    \"Intermediate\": [\"Group I Paper 1\", \"Group I Paper 2\", \"Group I Paper 3\", \"Group I Paper 4\", \n                    \"Group II Paper 5\", \"Group II Paper 6\", \"Group II Paper 7\", \"Group II Paper 8\"],\n    \"Final\": [\"Group I Paper 1\", \"Group I Paper 2\", \"Group I Paper 3\", \"Group I Paper 4\",\n             \"Group II Paper 5\", \"Group II Paper 6\", \"Group II Paper 7\", \"Group II Paper 8\"]\n}\n","size_bytes":1610},"curriculum_manager.py":{"content":"\"\"\"\nCA Curriculum Manager for Hierarchical Navigation\nParses and manages the CA curriculum structure for cascading dropdowns\n\"\"\"\n\nimport re\nimport json\nimport os\nfrom typing import Dict, List, Optional, Any\nimport logging\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nclass CurriculumManager:\n    def __init__(self):\n        self.curriculum_data = {}\n        # Configuration for curriculum source\n        self.curriculum_source = os.getenv('CURRICULUM_SOURCE', 'json')  # 'json' or 'tree'\n        self.json_curriculum_path = os.getenv('CURRICULUM_JSON_PATH', 'attached_assets/New document 1_1758323551064.json')\n        self.tree_curriculum_path = 'attached_assets/output_1758321057482.txt'\n        self._load_curriculum_structure()\n    \n    def _load_curriculum_structure(self):\n        \"\"\"Load and parse the curriculum structure from JSON or text file\"\"\"\n        try:\n            # Try JSON first if available\n            if self.curriculum_source == 'json' and os.path.exists(self.json_curriculum_path):\n                logger.info(f\"Loading curriculum from JSON: {self.json_curriculum_path}\")\n                with open(self.json_curriculum_path, 'r', encoding='utf-8') as f:\n                    json_data = json.load(f)\n                self.curriculum_data = self._parse_curriculum_json(json_data)\n                logger.info(f\"Successfully loaded JSON curriculum with {len(self.curriculum_data)} levels\")\n                return\n            \n            # Fallback to tree parsing\n            logger.info(f\"Loading curriculum from tree structure: {self.tree_curriculum_path}\")\n            with open(self.tree_curriculum_path, 'r', encoding='utf-8') as f:\n                content = f.read()\n            \n            self.curriculum_data = self._parse_curriculum_tree(content)\n            logger.info(f\"Loaded tree curriculum with {len(self.curriculum_data)} levels\")\n            \n        except Exception as e:\n            logger.error(f\"Failed to load curriculum: {e}\")\n            # Fallback to basic structure\n            self._create_fallback_structure()\n    \n    def _parse_curriculum_tree(self, content: str) -> Dict[str, Any]:\n        \"\"\"Parse the tree structure from the text content\"\"\"\n        curriculum = {}\n        current_level = None\n        current_paper = None\n        current_module = None\n        current_chapter = None\n        \n        lines = content.split('\\n')\n        \n        for line in lines:\n            if not line.strip():\n                continue\n                \n            # Clean the line by removing tree characters and getting the content\n            clean_line = line.strip()\n            # Remove tree drawing characters\n            clean_line = re.sub(r'^[â”‚â”œâ””\\sâ”€]*', '', clean_line).strip()\n            \n            if not clean_line or clean_line == '.':\n                continue\n            \n            # Count tree depth by counting the tree structure\n            # Pattern is: â”‚ + two non-breaking spaces + one regular space\n            tree_pattern = 'â”‚\\xa0\\xa0 '  # â”‚ + two non-breaking spaces (Unicode 160) + one regular space\n            tree_depth = line.count(tree_pattern) + (1 if ('â”œâ”€â”€' in line or 'â””â”€â”€' in line) else 0)\n            \n            # Level 0: CA Levels (Foundation, Intermediate, Final)\n            if tree_depth == 1 and any(level in clean_line.lower() for level in ['foundation', 'intermediate', 'final']):\n                current_level = self._normalize_level_name(clean_line)\n                curriculum[current_level] = {}\n                current_paper = None\n                current_module = None\n                current_chapter = None\n                \n            # Level 1: Papers\n            elif tree_depth == 2 and current_level and 'paper' in clean_line.lower():\n                current_paper = self._clean_paper_name(clean_line)\n                curriculum[current_level][current_paper] = {}\n                current_module = None\n                current_chapter = None\n                \n            # Level 2: Modules or Chapters\n            elif tree_depth == 3 and current_level and current_paper:\n                if 'module' in clean_line.lower() or 'part' in clean_line.lower():\n                    # This is a module\n                    current_module = self._clean_module_name(clean_line)\n                    curriculum[current_level][current_paper][current_module] = {}\n                    current_chapter = None\n                elif 'chapter' in clean_line.lower():\n                    # This is a direct chapter (no modules)\n                    current_chapter = self._clean_chapter_name(clean_line)\n                    if 'chapters' not in curriculum[current_level][current_paper]:\n                        curriculum[current_level][current_paper]['chapters'] = {}\n                    curriculum[current_level][current_paper]['chapters'][current_chapter] = {}\n                    \n            # Level 3: Chapters (under modules) or Units\n            elif tree_depth == 4 and current_level and current_paper:\n                if current_module and 'chapter' in clean_line.lower():\n                    # Chapter under module\n                    current_chapter = self._clean_chapter_name(clean_line)\n                    curriculum[current_level][current_paper][current_module][current_chapter] = {}\n                elif current_chapter and 'unit' in clean_line.lower():\n                    # Unit under direct chapter\n                    unit_name = self._clean_unit_name(clean_line)\n                    if 'units' not in curriculum[current_level][current_paper]['chapters'][current_chapter]:\n                        curriculum[current_level][current_paper]['chapters'][current_chapter]['units'] = {}\n                    curriculum[current_level][current_paper]['chapters'][current_chapter]['units'][unit_name] = {}\n                    \n            # Level 4: Units (under module chapters)\n            elif tree_depth == 5 and current_level and current_paper and current_module and current_chapter:\n                if 'unit' in clean_line.lower():\n                    unit_name = self._clean_unit_name(clean_line)\n                    if 'units' not in curriculum[current_level][current_paper][current_module][current_chapter]:\n                        curriculum[current_level][current_paper][current_module][current_chapter]['units'] = {}\n                    curriculum[current_level][current_paper][current_module][current_chapter]['units'][unit_name] = {}\n        \n        return curriculum\n    \n    def _parse_curriculum_json(self, json_data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Parse the curriculum structure from JSON data\"\"\"\n        curriculum = {}\n        \n        try:\n            if 'CA_Course_Structure' not in json_data:\n                logger.error(\"JSON data missing 'CA_Course_Structure' key\")\n                return curriculum\n            \n            ca_structure = json_data['CA_Course_Structure']\n            \n            for level_name, level_data in ca_structure.items():\n                # Normalize level name\n                normalized_level = self._normalize_level_name(level_name)\n                curriculum[normalized_level] = {}\n                \n                for paper_name, paper_data in level_data.items():\n                    # Clean paper name\n                    clean_paper = self._clean_paper_name(paper_name)\n                    curriculum[normalized_level][clean_paper] = {}\n                    \n                    # Check if paper has modules or direct chapters\n                    has_modules = any('module' in key.lower() for key in paper_data.keys())\n                    \n                    if has_modules:\n                        # Paper has modules\n                        for module_name, module_data in paper_data.items():\n                            if 'module' in module_name.lower():\n                                clean_module = self._clean_module_name(module_name)\n                                curriculum[normalized_level][clean_paper][clean_module] = {}\n                                \n                                # Add chapters under module\n                                if isinstance(module_data, dict):\n                                    for chapter_name, chapter_data in module_data.items():\n                                        clean_chapter = self._clean_chapter_name(chapter_name)\n                                        curriculum[normalized_level][clean_paper][clean_module][clean_chapter] = {}\n                                        \n                                        # Check for units in chapter\n                                        if isinstance(chapter_data, dict) and chapter_data:\n                                            curriculum[normalized_level][clean_paper][clean_module][clean_chapter]['units'] = {}\n                                            for unit_name in chapter_data.keys():\n                                                clean_unit = self._clean_unit_name(unit_name)\n                                                curriculum[normalized_level][clean_paper][clean_module][clean_chapter]['units'][clean_unit] = {}\n                    else:\n                        # Paper has direct chapters (no modules)\n                        curriculum[normalized_level][clean_paper]['chapters'] = {}\n                        \n                        for chapter_name, chapter_data in paper_data.items():\n                            clean_chapter = self._clean_chapter_name(chapter_name)\n                            curriculum[normalized_level][clean_paper]['chapters'][clean_chapter] = {}\n                            \n                            # Check for units in chapter\n                            if isinstance(chapter_data, dict) and chapter_data:\n                                curriculum[normalized_level][clean_paper]['chapters'][clean_chapter]['units'] = {}\n                                for unit_name in chapter_data.keys():\n                                    clean_unit = self._clean_unit_name(unit_name)\n                                    curriculum[normalized_level][clean_paper]['chapters'][clean_chapter]['units'][clean_unit] = {}\n            \n            return curriculum\n            \n        except Exception as e:\n            logger.error(f\"Error parsing JSON curriculum: {e}\")\n            return {}\n    \n    def _normalize_level_name(self, level: str) -> str:\n        \"\"\"Normalize level names to consistent format\"\"\"\n        level_lower = level.lower()\n        if 'foundation' in level_lower:\n            return 'Foundation'\n        elif 'intermediate' in level_lower:\n            return 'Intermediate'\n        elif 'final' in level_lower:\n            return 'Final'\n        return level.title()\n    \n    def _clean_paper_name(self, paper: str) -> str:\n        \"\"\"Clean paper names\"\"\"\n        # Remove file extensions and clean up\n        paper = re.sub(r'\\.pdf$', '', paper)\n        return paper.strip()\n    \n    def _clean_module_name(self, module: str) -> str:\n        \"\"\"Clean module names\"\"\"\n        module = re.sub(r'\\.pdf$', '', module)\n        return module.strip()\n    \n    def _clean_chapter_name(self, chapter: str) -> str:\n        \"\"\"Clean chapter names\"\"\"\n        chapter = re.sub(r'\\.pdf$', '', chapter)\n        return chapter.strip()\n    \n    def _clean_unit_name(self, unit: str) -> str:\n        \"\"\"Clean unit names\"\"\"\n        unit = re.sub(r'\\.pdf$', '', unit)\n        return unit.strip()\n    \n    def _create_fallback_structure(self):\n        \"\"\"Create a basic fallback structure if parsing fails\"\"\"\n        self.curriculum_data = {\n            'Foundation': {\n                'Paper 1: Accounting': {'chapters': {}},\n                'Paper 2: Business Laws': {'chapters': {}},\n                'Paper 3: Quantitative Aptitude': {'chapters': {}},\n                'Paper 4: Business Economics': {'chapters': {}}\n            },\n            'Intermediate': {\n                'Paper 1: Advanced Accounting': {'chapters': {}},\n                'Paper 2: Corporate and Other Laws': {'chapters': {}},\n                'Paper 3: Taxation': {'chapters': {}},\n                'Paper 4: Cost and Management Accounting': {'chapters': {}}\n            },\n            'Final': {\n                'Paper 1: Financial Reporting': {'chapters': {}},\n                'Paper 2: Advanced Financial Management': {'chapters': {}},\n                'Paper 3: Advanced Auditing and Professional Ethics': {'chapters': {}},\n                'Paper 4: Direct Tax Laws': {'chapters': {}},\n                'Paper 5: Indirect Tax Laws': {'chapters': {}}\n            }\n        }\n    \n    # Public API methods for UI components\n    \n    def get_levels(self) -> List[str]:\n        \"\"\"Get all available CA levels\"\"\"\n        return list(self.curriculum_data.keys())\n    \n    def get_papers(self, level: str) -> List[str]:\n        \"\"\"Get papers for a specific level\"\"\"\n        if level not in self.curriculum_data:\n            return []\n        return list(self.curriculum_data[level].keys())\n    \n    def get_modules(self, level: str, paper: str) -> List[str]:\n        \"\"\"Get modules for a specific level and paper\"\"\"\n        if not level or not paper or level not in self.curriculum_data or paper not in self.curriculum_data[level]:\n            return []\n        \n        paper_data = self.curriculum_data[level][paper]\n        modules = []\n        \n        # Get all keys that are not 'chapters'\n        for key in paper_data.keys():\n            if key != 'chapters':\n                modules.append(key)\n        \n        return modules\n    \n    def has_modules(self, level: str, paper: str) -> bool:\n        \"\"\"Check if a paper has modules\"\"\"\n        if not level or not paper:\n            return False\n        modules = self.get_modules(level, paper)\n        return len(modules) > 0\n    \n    def get_chapters(self, level: str, paper: str, module: Optional[str] = None) -> List[str]:\n        \"\"\"Get chapters for a specific level, paper, and optionally module\"\"\"\n        if not level or not paper or level not in self.curriculum_data or paper not in self.curriculum_data[level]:\n            return []\n        \n        paper_data = self.curriculum_data[level][paper]\n        \n        if module:\n            # Get chapters from specific module\n            if module not in paper_data:\n                return []\n            module_data = paper_data[module]\n            return [key for key in module_data.keys() if key != 'units']\n        else:\n            # Get chapters directly from paper (no modules)\n            if 'chapters' in paper_data:\n                return list(paper_data['chapters'].keys())\n            return []\n    \n    def get_units(self, level: str, paper: str, chapter: str, module: Optional[str] = None) -> List[str]:\n        \"\"\"Get units for a specific level, paper, chapter, and optionally module\"\"\"\n        if not level or not paper or not chapter or level not in self.curriculum_data or paper not in self.curriculum_data[level]:\n            return []\n        \n        paper_data = self.curriculum_data[level][paper]\n        \n        if module:\n            # Get units from module chapter\n            if module not in paper_data or chapter not in paper_data[module]:\n                return []\n            chapter_data = paper_data[module][chapter]\n            if 'units' in chapter_data:\n                return list(chapter_data['units'].keys())\n        else:\n            # Get units from direct chapter\n            if 'chapters' not in paper_data or chapter not in paper_data['chapters']:\n                return []\n            chapter_data = paper_data['chapters'][chapter]\n            if 'units' in chapter_data:\n                return list(chapter_data['units'].keys())\n        \n        return []\n    \n    def has_units(self, level: str, paper: str, chapter: str, module: Optional[str] = None) -> bool:\n        \"\"\"Check if a chapter has units\"\"\"\n        if not level or not paper or not chapter:\n            return False\n        units = self.get_units(level, paper, chapter, module)\n        return len(units) > 0\n    \n    def get_hierarchy_info(self, level: str, paper: Optional[str] = None, module: Optional[str] = None, \n                          chapter: Optional[str] = None, unit: Optional[str] = None) -> Dict[str, Any]:\n        \"\"\"Get comprehensive hierarchy information for a given path\"\"\"\n        info = {\n            'level': level,\n            'paper': paper,\n            'module': module,\n            'chapter': chapter,\n            'unit': unit,\n            'has_modules': False,\n            'has_units': False,\n            'available_papers': [],\n            'available_modules': [],\n            'available_chapters': [],\n            'available_units': []\n        }\n        \n        if level:\n            info['available_papers'] = self.get_papers(level)\n            \n        if paper:\n            info['has_modules'] = self.has_modules(level, paper)\n            info['available_modules'] = self.get_modules(level, paper)\n            \n            if not info['has_modules']:\n                info['available_chapters'] = self.get_chapters(level, paper)\n                \n        if module and paper:\n            info['available_chapters'] = self.get_chapters(level, paper, module)\n            \n        if chapter and paper:\n            info['has_units'] = self.has_units(level, paper, chapter, module)\n            info['available_units'] = self.get_units(level, paper, chapter, module)\n            \n        return info\n    \n    def validate_hierarchy(self, level: str, paper: Optional[str] = None, module: Optional[str] = None,\n                          chapter: Optional[str] = None, unit: Optional[str] = None) -> bool:\n        \"\"\"Validate if the given hierarchy path is valid\"\"\"\n        try:\n            if level not in self.curriculum_data:\n                return False\n                \n            if paper and paper not in self.curriculum_data[level]:\n                return False\n                \n            if module and paper:\n                if not self.has_modules(level, paper) or module not in self.get_modules(level, paper):\n                    return False\n                    \n            if chapter and paper:\n                valid_chapters = self.get_chapters(level, paper, module)\n                if chapter not in valid_chapters:\n                    return False\n                    \n            if unit and paper and chapter:\n                valid_units = self.get_units(level, paper, chapter, module)\n                if unit not in valid_units:\n                    return False\n                    \n            return True\n            \n        except Exception as e:\n            logger.error(f\"Hierarchy validation error: {e}\")\n            return False\n    \n    def get_display_path(self, level: str, paper: Optional[str] = None, module: Optional[str] = None,\n                        chapter: Optional[str] = None, unit: Optional[str] = None) -> str:\n        \"\"\"Generate a human-readable display path\"\"\"\n        path_parts = [level]\n        \n        if paper:\n            path_parts.append(paper)\n        if module:\n            path_parts.append(module)\n        if chapter:\n            path_parts.append(chapter)\n        if unit:\n            path_parts.append(unit)\n            \n        return \" â†’ \".join(path_parts)\n\n# Global curriculum manager instance\ncurriculum_manager = CurriculumManager()","size_bytes":19408},"curriculum_ui.py":{"content":"\"\"\"\nCurriculum UI Components for Hierarchical Navigation\nProvides cascading dropdown components for CA curriculum structure\n\"\"\"\n\nimport streamlit as st\nfrom typing import Dict, List, Optional, Tuple, Any\nfrom curriculum_manager import curriculum_manager\n\nclass CurriculumSelector:\n    \"\"\"Handles hierarchical curriculum selection with cascading dropdowns\"\"\"\n    \n    def __init__(self, prefix: str = \"curriculum\"):\n        \"\"\"\n        Initialize curriculum selector with a unique prefix for session state\n        \n        Args:\n            prefix: Unique prefix for session state keys\n        \"\"\"\n        self.prefix = prefix\n        self._init_session_state()\n    \n    def _init_session_state(self):\n        \"\"\"Initialize session state for curriculum selection\"\"\"\n        default_values = {\n            f\"{self.prefix}_level\": None,\n            f\"{self.prefix}_paper\": None,\n            f\"{self.prefix}_module\": None,\n            f\"{self.prefix}_chapter\": None,\n            f\"{self.prefix}_unit\": None\n        }\n        \n        for key, default in default_values.items():\n            if key not in st.session_state:\n                st.session_state[key] = default\n    \n    def _reset_dependent_selections(self, from_level: str):\n        \"\"\"Reset dependent selections when a higher level changes\"\"\"\n        reset_map = {\n            'level': ['paper', 'module', 'chapter', 'unit'],\n            'paper': ['module', 'chapter', 'unit'],\n            'module': ['chapter', 'unit'],\n            'chapter': ['unit']\n        }\n        \n        if from_level in reset_map:\n            for dependent in reset_map[from_level]:\n                key = f\"{self.prefix}_{dependent}\"\n                if key in st.session_state:\n                    st.session_state[key] = None\n    \n    def render_level_selector(self, label: str = \"CA Level\", help_text: str = None) -> Optional[str]:\n        \"\"\"Render CA level dropdown\"\"\"\n        levels = curriculum_manager.get_levels()\n        \n        if not levels:\n            st.error(\"No CA levels available. Please check curriculum data.\")\n            return None\n        \n        # Add empty option for selection\n        options = [\"Select Level\"] + levels\n        current_index = 0\n        \n        if st.session_state.get(f\"{self.prefix}_level\"):\n            try:\n                current_index = options.index(st.session_state[f\"{self.prefix}_level\"])\n            except ValueError:\n                current_index = 0\n        \n        selected = st.selectbox(\n            label,\n            options=options,\n            index=current_index,\n            help=help_text,\n            key=f\"{self.prefix}_level_selectbox\"\n        )\n        \n        if selected and selected != \"Select Level\":\n            if st.session_state.get(f\"{self.prefix}_level\") != selected:\n                self._reset_dependent_selections('level')\n            st.session_state[f\"{self.prefix}_level\"] = selected\n            return selected\n        else:\n            st.session_state[f\"{self.prefix}_level\"] = None\n            self._reset_dependent_selections('level')\n            return None\n    \n    def render_paper_selector(self, label: str = \"Paper\", help_text: str = None) -> Optional[str]:\n        \"\"\"Render paper dropdown based on selected level\"\"\"\n        level = st.session_state.get(f\"{self.prefix}_level\")\n        \n        if not level:\n            st.selectbox(label, [\"Select Level First\"], disabled=True, help=\"Please select a CA level first\")\n            return None\n        \n        papers = curriculum_manager.get_papers(level)\n        \n        if not papers:\n            st.selectbox(label, [\"No papers available\"], disabled=True)\n            return None\n        \n        options = [\"Select Paper\"] + papers\n        current_index = 0\n        \n        if st.session_state.get(f\"{self.prefix}_paper\"):\n            try:\n                current_index = options.index(st.session_state[f\"{self.prefix}_paper\"])\n            except ValueError:\n                current_index = 0\n        \n        selected = st.selectbox(\n            label,\n            options=options,\n            index=current_index,\n            help=help_text,\n            key=f\"{self.prefix}_paper_selectbox\"\n        )\n        \n        if selected and selected != \"Select Paper\":\n            if st.session_state.get(f\"{self.prefix}_paper\") != selected:\n                self._reset_dependent_selections('paper')\n            st.session_state[f\"{self.prefix}_paper\"] = selected\n            return selected\n        else:\n            st.session_state[f\"{self.prefix}_paper\"] = None\n            self._reset_dependent_selections('paper')\n            return None\n    \n    def render_module_selector(self, label: str = \"Module\", help_text: str = None) -> Optional[str]:\n        \"\"\"Render module dropdown based on selected level and paper\"\"\"\n        level = st.session_state.get(f\"{self.prefix}_level\")\n        paper = st.session_state.get(f\"{self.prefix}_paper\")\n        \n        if not level or not paper:\n            st.selectbox(label, [\"Select Paper First\"], disabled=True, help=\"Please select a paper first\")\n            return None\n        \n        # Check if paper has modules\n        if not curriculum_manager.has_modules(level, paper):\n            # Skip module selection - no modules for this paper\n            st.info(\"â„¹ï¸ This paper has no modules - proceeding directly to chapters\")\n            st.session_state[f\"{self.prefix}_module\"] = None\n            return None\n        \n        modules = curriculum_manager.get_modules(level, paper)\n        \n        if not modules:\n            st.selectbox(label, [\"No modules available\"], disabled=True)\n            return None\n        \n        options = [\"Select Module\"] + modules\n        current_index = 0\n        \n        if st.session_state.get(f\"{self.prefix}_module\"):\n            try:\n                current_index = options.index(st.session_state[f\"{self.prefix}_module\"])\n            except ValueError:\n                current_index = 0\n        \n        selected = st.selectbox(\n            label,\n            options=options,\n            index=current_index,\n            help=help_text,\n            key=f\"{self.prefix}_module_selectbox\"\n        )\n        \n        if selected and selected != \"Select Module\":\n            if st.session_state.get(f\"{self.prefix}_module\") != selected:\n                self._reset_dependent_selections('module')\n            st.session_state[f\"{self.prefix}_module\"] = selected\n            return selected\n        else:\n            st.session_state[f\"{self.prefix}_module\"] = None\n            self._reset_dependent_selections('module')\n            return None\n    \n    def render_chapter_selector(self, label: str = \"Chapter\", help_text: str = None) -> Optional[str]:\n        \"\"\"Render chapter dropdown based on selected level, paper, and module\"\"\"\n        level = st.session_state.get(f\"{self.prefix}_level\")\n        paper = st.session_state.get(f\"{self.prefix}_paper\")\n        module = st.session_state.get(f\"{self.prefix}_module\")\n        \n        if not level or not paper:\n            st.selectbox(label, [\"Select Paper First\"], disabled=True, help=\"Please select a paper first\")\n            return None\n        \n        # Check if we need module selection\n        has_modules = curriculum_manager.has_modules(level, paper)\n        if has_modules and not module:\n            st.selectbox(label, [\"Select Module First\"], disabled=True, help=\"Please select a module first\")\n            return None\n        \n        chapters = curriculum_manager.get_chapters(level, paper, module)\n        \n        if not chapters:\n            st.selectbox(label, [\"No chapters available\"], disabled=True)\n            return None\n        \n        options = [\"Select Chapter\"] + chapters\n        current_index = 0\n        \n        if st.session_state.get(f\"{self.prefix}_chapter\"):\n            try:\n                current_index = options.index(st.session_state[f\"{self.prefix}_chapter\"])\n            except ValueError:\n                current_index = 0\n        \n        selected = st.selectbox(\n            label,\n            options=options,\n            index=current_index,\n            help=help_text,\n            key=f\"{self.prefix}_chapter_selectbox\"\n        )\n        \n        if selected and selected != \"Select Chapter\":\n            if st.session_state.get(f\"{self.prefix}_chapter\") != selected:\n                self._reset_dependent_selections('chapter')\n            st.session_state[f\"{self.prefix}_chapter\"] = selected\n            return selected\n        else:\n            st.session_state[f\"{self.prefix}_chapter\"] = None\n            self._reset_dependent_selections('chapter')\n            return None\n    \n    def render_unit_selector(self, label: str = \"Unit\", help_text: str = None) -> Optional[str]:\n        \"\"\"Render unit dropdown based on selected level, paper, module, and chapter\"\"\"\n        level = st.session_state.get(f\"{self.prefix}_level\")\n        paper = st.session_state.get(f\"{self.prefix}_paper\")\n        module = st.session_state.get(f\"{self.prefix}_module\")\n        chapter = st.session_state.get(f\"{self.prefix}_chapter\")\n        \n        if not level or not paper or not chapter:\n            st.selectbox(label, [\"Select Chapter First\"], disabled=True, help=\"Please select a chapter first\")\n            return None\n        \n        # Check if chapter has units\n        if not curriculum_manager.has_units(level, paper, chapter, module):\n            # Skip unit selection - no units for this chapter\n            st.info(\"â„¹ï¸ This chapter has no units - selection complete at chapter level\")\n            st.session_state[f\"{self.prefix}_unit\"] = None\n            return None\n        \n        units = curriculum_manager.get_units(level, paper, chapter, module)\n        \n        if not units:\n            st.selectbox(label, [\"No units available\"], disabled=True)\n            return None\n        \n        options = [\"Select Unit\"] + units\n        current_index = 0\n        \n        if st.session_state.get(f\"{self.prefix}_unit\"):\n            try:\n                current_index = options.index(st.session_state[f\"{self.prefix}_unit\"])\n            except ValueError:\n                current_index = 0\n        \n        selected = st.selectbox(\n            label,\n            options=options,\n            index=current_index,\n            help=help_text,\n            key=f\"{self.prefix}_unit_selectbox\"\n        )\n        \n        if selected and selected != \"Select Unit\":\n            st.session_state[f\"{self.prefix}_unit\"] = selected\n            return selected\n        else:\n            st.session_state[f\"{self.prefix}_unit\"] = None\n            return None\n    \n    def render_complete_selector(self, title: str = \"Select Curriculum Hierarchy\",\n                               show_path: bool = True, columns: bool = True) -> Dict[str, Optional[str]]:\n        \"\"\"Render complete curriculum selector with all levels\"\"\"\n        \n        if title:\n            st.subheader(title)\n        \n        if columns:\n            # Render in columns following proper hierarchy: Level â†’ Paper â†’ Module â†’ Chapter â†’ Unit\n            col1, col2 = st.columns(2)\n            \n            with col1:\n                level = self.render_level_selector(\"CA Level\")\n                paper = self.render_paper_selector(\"Paper\")\n                module = self.render_module_selector(\"Module\")\n                \n            with col2:\n                chapter = self.render_chapter_selector(\"Chapter\")\n                unit = self.render_unit_selector(\"Unit\")\n        else:\n            # Render in single column\n            level = self.render_level_selector(\"CA Level\")\n            paper = self.render_paper_selector(\"Paper\")\n            module = self.render_module_selector(\"Module\")\n            chapter = self.render_chapter_selector(\"Chapter\")\n            unit = self.render_unit_selector(\"Unit\")\n        \n        # Show current path\n        if show_path and level:\n            path = curriculum_manager.get_display_path(level, paper, module, chapter, unit)\n            st.info(f\"ğŸ“ **Current Path:** {path}\")\n        \n        return {\n            'level': level,\n            'paper': paper,\n            'module': module,\n            'chapter': chapter,\n            'unit': unit\n        }\n    \n    def get_current_selection(self) -> Dict[str, Optional[str]]:\n        \"\"\"Get current curriculum selection\"\"\"\n        return {\n            'level': st.session_state.get(f\"{self.prefix}_level\"),\n            'paper': st.session_state.get(f\"{self.prefix}_paper\"),\n            'module': st.session_state.get(f\"{self.prefix}_module\"),\n            'chapter': st.session_state.get(f\"{self.prefix}_chapter\"),\n            'unit': st.session_state.get(f\"{self.prefix}_unit\")\n        }\n    \n    def is_complete_selection(self) -> bool:\n        \"\"\"Check if we have a complete, valid selection for document upload\"\"\"\n        selection = self.get_current_selection()\n        level = selection['level']\n        paper = selection['paper']\n        module = selection['module']\n        chapter = selection['chapter']\n        unit = selection['unit']\n        \n        if not level or not paper:\n            return False\n        \n        # Check if we need module but don't have it\n        if curriculum_manager.has_modules(level, paper) and not module:\n            return False\n        \n        # Must have chapter\n        if not chapter:\n            return False\n        \n        # Check if we need unit but don't have it\n        if curriculum_manager.has_units(level, paper, chapter, module) and not unit:\n            return False\n        \n        return True\n    \n    def get_missing_selections(self) -> List[str]:\n        \"\"\"Get list of missing required selections\"\"\"\n        missing = []\n        selection = self.get_current_selection()\n        \n        if not selection['level']:\n            missing.append(\"CA Level\")\n        elif not selection['paper']:\n            missing.append(\"Paper\")\n        else:\n            level = selection['level']\n            paper = selection['paper']\n            module = selection['module']\n            chapter = selection['chapter']\n            \n            # Check if module is required but missing\n            if curriculum_manager.has_modules(level, paper) and not module:\n                missing.append(\"Module\")\n            \n            # Check if chapter is missing\n            if not chapter:\n                missing.append(\"Chapter\")\n            \n            # Check if unit is required but missing\n            if chapter and curriculum_manager.has_units(level, paper, chapter, module) and not selection['unit']:\n                missing.append(\"Unit\")\n        \n        return missing\n    \n    def render_selection_status(self):\n        \"\"\"Render current selection status with helpful feedback\"\"\"\n        if self.is_complete_selection():\n            st.success(\"âœ… Complete curriculum selection - ready to proceed!\")\n        else:\n            missing = self.get_missing_selections()\n            if missing:\n                st.warning(f\"âš ï¸ Please select: {', '.join(missing)}\")\n    \n    def clear_selection(self):\n        \"\"\"Clear all selections\"\"\"\n        keys_to_clear = [\n            f\"{self.prefix}_level\",\n            f\"{self.prefix}_paper\", \n            f\"{self.prefix}_module\",\n            f\"{self.prefix}_chapter\",\n            f\"{self.prefix}_unit\"\n        ]\n        \n        for key in keys_to_clear:\n            if key in st.session_state:\n                st.session_state[key] = None\n\ndef render_curriculum_filter(prefix: str = \"filter\", title: str = \"Filter by Curriculum\",\n                           show_clear: bool = True) -> Dict[str, Optional[str]]:\n    \"\"\"\n    Render curriculum filter component for questions/search\n    Returns current filter selection\n    \"\"\"\n    selector = CurriculumSelector(prefix)\n    \n    with st.expander(title, expanded=False):\n        selection = selector.render_complete_selector(title=\"\", show_path=True, columns=True)\n        \n        if show_clear:\n            col1, col2 = st.columns([3, 1])\n            with col2:\n                if st.button(\"Clear Filters\", key=f\"{prefix}_clear\"):\n                    selector.clear_selection()\n                    st.rerun()\n    \n    return selection","size_bytes":16232},"database.py":{"content":"import psycopg2\nfrom psycopg2.extras import RealDictCursor\nimport numpy as np\nimport json\nfrom typing import List, Dict, Any, Optional\nimport logging\nfrom config import DATABASE_URL, PGHOST, PGPORT, PGDATABASE, PGUSER, PGPASSWORD\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nclass VectorDatabase:\n    def __init__(self):\n        self.connection_params = {\n            'host': PGHOST,\n            'port': PGPORT,\n            'database': PGDATABASE,\n            'user': PGUSER,\n            'password': PGPASSWORD\n        }\n        self.init_database()\n    \n    def get_connection(self):\n        \"\"\"Get database connection\"\"\"\n        try:\n            conn = psycopg2.connect(\n                host=self.connection_params['host'],\n                port=self.connection_params['port'],\n                database=self.connection_params['database'],\n                user=self.connection_params['user'],\n                password=self.connection_params['password']\n            )\n            return conn\n        except Exception as e:\n            logger.error(f\"Database connection failed: {e}\")\n            raise\n    \n    def init_database(self):\n        \"\"\"Initialize database with required tables and extensions\"\"\"\n        try:\n            conn = self.get_connection()\n            cur = conn.cursor()\n            \n            # Enable pgvector extension\n            cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector;\")\n            \n            # Create documents table for text chunks\n            cur.execute(\"\"\"\n                CREATE TABLE IF NOT EXISTS documents (\n                    id SERIAL PRIMARY KEY,\n                    file_id TEXT NOT NULL,\n                    file_name TEXT NOT NULL,\n                    content TEXT NOT NULL,\n                    embedding vector(1536),\n                    metadata JSONB,\n                    chunk_index INTEGER,\n                    level TEXT,\n                    paper TEXT,\n                    module TEXT,\n                    chapter TEXT,\n                    unit TEXT,\n                    content_type TEXT DEFAULT 'text',\n                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n                );\n            \"\"\")\n            \n            # Create tables table for extracted tables\n            cur.execute(\"\"\"\n                CREATE TABLE IF NOT EXISTS tables (\n                    id SERIAL PRIMARY KEY,\n                    file_id TEXT NOT NULL,\n                    file_name TEXT NOT NULL,\n                    table_data JSONB NOT NULL,\n                    table_html TEXT,\n                    embedding vector(1536),\n                    context_before TEXT,\n                    context_after TEXT,\n                    page_number INTEGER,\n                    table_index INTEGER,\n                    level TEXT,\n                    paper TEXT,\n                    module TEXT,\n                    chapter TEXT,\n                    unit TEXT,\n                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n                );\n            \"\"\")\n            \n            # Create file_metadata table\n            cur.execute(\"\"\"\n                CREATE TABLE IF NOT EXISTS file_metadata (\n                    id SERIAL PRIMARY KEY,\n                    file_id TEXT UNIQUE NOT NULL,\n                    file_name TEXT NOT NULL,\n                    appwrite_file_id TEXT,\n                    level TEXT,\n                    paper TEXT,\n                    module TEXT,\n                    chapter TEXT,\n                    unit TEXT,\n                    total_pages INTEGER,\n                    processing_status TEXT DEFAULT 'pending',\n                    upload_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n                    processed_date TIMESTAMP\n                );\n            \"\"\")\n            \n            # Create indexes for better performance\n            cur.execute(\"CREATE INDEX IF NOT EXISTS idx_documents_embedding ON documents USING ivfflat (embedding vector_cosine_ops);\")\n            cur.execute(\"CREATE INDEX IF NOT EXISTS idx_tables_embedding ON tables USING ivfflat (embedding vector_cosine_ops);\")\n            cur.execute(\"CREATE INDEX IF NOT EXISTS idx_documents_metadata ON documents USING gin(metadata);\")\n            cur.execute(\"CREATE INDEX IF NOT EXISTS idx_documents_level ON documents(level);\")\n            cur.execute(\"CREATE INDEX IF NOT EXISTS idx_documents_paper ON documents(paper);\")\n            cur.execute(\"CREATE INDEX IF NOT EXISTS idx_tables_level ON tables(level);\")\n            cur.execute(\"CREATE INDEX IF NOT EXISTS idx_tables_paper ON tables(paper);\")\n            \n            conn.commit()\n            cur.close()\n            conn.close()\n            logger.info(\"Database initialized successfully\")\n            \n        except Exception as e:\n            logger.error(f\"Database initialization failed: {e}\")\n            raise\n    \n    def store_document_chunk(self, file_id: str, file_name: str, content: str, \n                           embedding: List[float], metadata: Dict, chunk_index: int,\n                           level: str = None, paper: str = None, module: str = None,\n                           chapter: str = None, unit: str = None) -> int:\n        \"\"\"Store a document chunk with its embedding\"\"\"\n        try:\n            conn = self.get_connection()\n            cur = conn.cursor()\n            \n            cur.execute(\"\"\"\n                INSERT INTO documents (file_id, file_name, content, embedding, metadata, \n                                     chunk_index, level, paper, module, chapter, unit)\n                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n                RETURNING id;\n            \"\"\", (file_id, file_name, content, embedding, json.dumps(metadata), \n                  chunk_index, level or '', paper or '', module or '', chapter or '', unit or ''))\n            \n            doc_id = cur.fetchone()[0]\n            conn.commit()\n            cur.close()\n            conn.close()\n            \n            return doc_id\n            \n        except Exception as e:\n            logger.error(f\"Failed to store document chunk: {e}\")\n            raise\n    \n    def store_table(self, file_id: str, file_name: str, table_data: Dict,\n                   table_html: str, embedding: List[float], context_before: str,\n                   context_after: str, page_number: int, table_index: int,\n                   level: str = None, paper: str = None, module: str = None,\n                   chapter: str = None, unit: str = None) -> int:\n        \"\"\"Store extracted table with its embedding\"\"\"\n        try:\n            conn = self.get_connection()\n            cur = conn.cursor()\n            \n            cur.execute(\"\"\"\n                INSERT INTO tables (file_id, file_name, table_data, table_html, embedding,\n                                  context_before, context_after, page_number, table_index,\n                                  level, paper, module, chapter, unit)\n                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n                RETURNING id;\n            \"\"\", (file_id, file_name, json.dumps(table_data), table_html, embedding,\n                  context_before, context_after, page_number, table_index,\n                  level or '', paper or '', module or '', chapter or '', unit or ''))\n            \n            table_id = cur.fetchone()[0]\n            conn.commit()\n            cur.close()\n            conn.close()\n            \n            return table_id\n            \n        except Exception as e:\n            logger.error(f\"Failed to store table: {e}\")\n            raise\n    \n    def store_file_metadata(self, file_id: str, file_name: str, appwrite_file_id: str,\n                           level: str, paper: str, module: str = None, chapter: str = None,\n                           unit: str = None, total_pages: int = 0) -> int:\n        \"\"\"Store file metadata\"\"\"\n        try:\n            conn = self.get_connection()\n            cur = conn.cursor()\n            \n            cur.execute(\"\"\"\n                INSERT INTO file_metadata (file_id, file_name, appwrite_file_id, level, paper,\n                                         module, chapter, unit, total_pages)\n                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\n                ON CONFLICT (file_id) DO UPDATE SET\n                    file_name = EXCLUDED.file_name,\n                    appwrite_file_id = EXCLUDED.appwrite_file_id,\n                    level = EXCLUDED.level,\n                    paper = EXCLUDED.paper,\n                    module = EXCLUDED.module,\n                    chapter = EXCLUDED.chapter,\n                    unit = EXCLUDED.unit,\n                    total_pages = EXCLUDED.total_pages\n                RETURNING id;\n            \"\"\", (file_id, file_name, appwrite_file_id, level, paper, module or '', chapter or '', unit or '', total_pages))\n            \n            metadata_id = cur.fetchone()[0]\n            conn.commit()\n            cur.close()\n            conn.close()\n            \n            return metadata_id\n            \n        except Exception as e:\n            logger.error(f\"Failed to store file metadata: {e}\")\n            raise\n    \n    def similarity_search_documents(self, query_embedding: List[float], top_k: int = 5,\n                                  level: str = None, paper: str = None, module: str = None,\n                                  chapter: str = None, unit: str = None) -> List[Dict]:\n        \"\"\"Search for similar document chunks\"\"\"\n        try:\n            conn = self.get_connection()\n            cur = conn.cursor(cursor_factory=RealDictCursor)\n            \n            # Build WHERE clause based on filters\n            where_conditions = []\n            filter_params = []\n            \n            if level:\n                where_conditions.append(\"level = %s\")\n                filter_params.append(level)\n            if paper:\n                where_conditions.append(\"paper = %s\")\n                filter_params.append(paper)\n            if module:\n                where_conditions.append(\"module = %s\")\n                filter_params.append(module)\n            if chapter:\n                where_conditions.append(\"chapter = %s\")\n                filter_params.append(chapter)\n            if unit:\n                where_conditions.append(\"unit = %s\")\n                filter_params.append(unit)\n            \n            where_clause = \" AND \" + \" AND \".join(where_conditions) if where_conditions else \"\"\n            \n            query = f\"\"\"\n                SELECT id, file_id, file_name, content, metadata, chunk_index,\n                       level, paper, module, chapter, unit,\n                       1 - (embedding <=> %s) as similarity\n                FROM documents\n                WHERE 1=1 {where_clause}\n                ORDER BY embedding <=> %s\n                LIMIT %s;\n            \"\"\"\n            \n            # Convert embedding to string format for pgvector\n            embedding_str = '[' + ','.join(map(str, query_embedding)) + ']'\n            \n            # Build params in correct order: embedding_str, filter_params..., embedding_str, top_k\n            params = [embedding_str] + filter_params + [embedding_str, top_k]\n            \n            cur.execute(query, params)\n            results = cur.fetchall() or []\n            \n            cur.close()\n            conn.close()\n            \n            return [dict(row) for row in results]\n            \n        except Exception as e:\n            logger.error(f\"Document similarity search failed: {e}\")\n            return []\n    \n    def similarity_search_tables(self, query_embedding: List[float], top_k: int = 5,\n                               level: str = None, paper: str = None, module: str = None,\n                               chapter: str = None, unit: str = None) -> List[Dict]:\n        \"\"\"Search for similar tables\"\"\"\n        try:\n            conn = self.get_connection()\n            cur = conn.cursor(cursor_factory=RealDictCursor)\n            \n            # Build WHERE clause based on filters\n            where_conditions = []\n            filter_params = []\n            \n            if level:\n                where_conditions.append(\"level = %s\")\n                filter_params.append(level)\n            if paper:\n                where_conditions.append(\"paper = %s\")\n                filter_params.append(paper)\n            if module:\n                where_conditions.append(\"module = %s\")\n                filter_params.append(module)\n            if chapter:\n                where_conditions.append(\"chapter = %s\")\n                filter_params.append(chapter)\n            if unit:\n                where_conditions.append(\"unit = %s\")\n                filter_params.append(unit)\n            \n            where_clause = \" AND \" + \" AND \".join(where_conditions) if where_conditions else \"\"\n            \n            query = f\"\"\"\n                SELECT id, file_id, file_name, table_data, table_html, context_before,\n                       context_after, page_number, table_index, level, paper, module,\n                       chapter, unit, 1 - (embedding <=> %s) as similarity\n                FROM tables\n                WHERE 1=1 {where_clause}\n                ORDER BY embedding <=> %s\n                LIMIT %s;\n            \"\"\"\n            \n            # Convert embedding to string format for pgvector\n            embedding_str = '[' + ','.join(map(str, query_embedding)) + ']'\n            \n            # Build params in correct order: embedding_str, filter_params..., embedding_str, top_k\n            params = [embedding_str] + filter_params + [embedding_str, top_k]\n            \n            cur.execute(query, params)\n            results = cur.fetchall() or []\n            \n            cur.close()\n            conn.close()\n            \n            return [dict(row) for row in results]\n            \n        except Exception as e:\n            logger.error(f\"Table similarity search failed: {e}\")\n            return []\n    \n    def get_file_metadata(self, file_id: str = None) -> List[Dict]:\n        \"\"\"Get file metadata\"\"\"\n        try:\n            conn = self.get_connection()\n            cur = conn.cursor(cursor_factory=RealDictCursor)\n            \n            if file_id:\n                cur.execute(\"SELECT * FROM file_metadata WHERE file_id = %s;\", (file_id,))\n            else:\n                cur.execute(\"SELECT * FROM file_metadata ORDER BY upload_date DESC;\")\n            \n            results = cur.fetchall()\n            cur.close()\n            conn.close()\n            \n            return [dict(row) for row in results]\n            \n        except Exception as e:\n            logger.error(f\"Failed to get file metadata: {e}\")\n            raise\n    \n    def update_processing_status(self, file_id: str, status: str):\n        \"\"\"Update file processing status\"\"\"\n        try:\n            conn = self.get_connection()\n            cur = conn.cursor()\n            \n            cur.execute(\"\"\"\n                UPDATE file_metadata \n                SET processing_status = %s, processed_date = CURRENT_TIMESTAMP\n                WHERE file_id = %s;\n            \"\"\", (status, file_id))\n            \n            conn.commit()\n            cur.close()\n            conn.close()\n            \n        except Exception as e:\n            logger.error(f\"Failed to update processing status: {e}\")\n            raise\n","size_bytes":15316},"embeddings.py":{"content":"from openai import AzureOpenAI\nfrom typing import List, Dict, Any\nimport logging\nimport numpy as np\nimport time\nfrom config import AZURE_OPENAI_ENDPOINT, AZURE_OPENAI_KEY, AZURE_OPENAI_VERSION, AZURE_EMBEDDINGS_DEPLOYMENT\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nclass AzureEmbeddings:\n    def __init__(self):\n        # Configure Azure OpenAI client\n        self.client = AzureOpenAI(\n            azure_endpoint=AZURE_OPENAI_ENDPOINT,\n            api_key=AZURE_OPENAI_KEY,\n            api_version=AZURE_OPENAI_VERSION\n        )\n        \n        self.deployment_name = AZURE_EMBEDDINGS_DEPLOYMENT\n        self.max_tokens = 8191  # Max tokens for ada-002\n        self.batch_size = 16    # Process embeddings in batches\n        \n    def get_embedding(self, text: str) -> List[float]:\n        \"\"\"Get embedding for a single text\"\"\"\n        try:\n            # Truncate text if too long\n            truncated_text = self._truncate_text(text)\n            \n            response = self.client.embeddings.create(\n                input=truncated_text,\n                model=self.deployment_name\n            )\n            \n            embedding = response.data[0].embedding\n            return embedding\n            \n        except Exception as e:\n            logger.error(f\"Failed to get embedding: {e}\")\n            raise\n    \n    def get_embeddings_batch(self, texts: List[str]) -> List[List[float]]:\n        \"\"\"Get embeddings for multiple texts in batches\"\"\"\n        try:\n            all_embeddings = []\n            \n            # Process in batches to avoid rate limits\n            for i in range(0, len(texts), self.batch_size):\n                batch = texts[i:i + self.batch_size]\n                \n                # Truncate texts in batch\n                truncated_batch = [self._truncate_text(text) for text in batch]\n                \n                # Get embeddings for batch\n                response = self.client.embeddings.create(\n                    input=truncated_batch,\n                    model=self.deployment_name\n                )\n                \n                # Extract embeddings\n                batch_embeddings = [item.embedding for item in response.data]\n                all_embeddings.extend(batch_embeddings)\n                \n                # Add small delay to respect rate limits\n                if i + self.batch_size < len(texts):\n                    time.sleep(0.1)\n                \n                logger.info(f\"Processed embeddings batch {i//self.batch_size + 1}/{(len(texts)-1)//self.batch_size + 1}\")\n            \n            return all_embeddings\n            \n        except Exception as e:\n            logger.error(f\"Failed to get batch embeddings: {e}\")\n            raise\n    \n    def _truncate_text(self, text: str) -> str:\n        \"\"\"Truncate text to fit within token limits\"\"\"\n        # Simple approximation: 4 characters â‰ˆ 1 token\n        max_chars = self.max_tokens * 4\n        \n        if len(text) <= max_chars:\n            return text\n        \n        # Truncate and add indication\n        truncated = text[:max_chars-50] + \"\\n[Text truncated for embedding...]\"\n        logger.warning(f\"Text truncated from {len(text)} to {len(truncated)} characters\")\n        \n        return truncated\n    \n    def get_table_embedding(self, table_text: str) -> List[float]:\n        \"\"\"Get embedding specifically optimized for table content\"\"\"\n        try:\n            # Add table-specific prefix to improve embedding quality\n            enhanced_text = f\"Financial/Accounting Table Data: {table_text}\"\n            \n            return self.get_embedding(enhanced_text)\n            \n        except Exception as e:\n            logger.error(f\"Failed to get table embedding: {e}\")\n            raise\n    \n    def get_query_embedding(self, query: str, context_type: str = \"general\") -> List[float]:\n        \"\"\"Get embedding for user queries with context awareness\"\"\"\n        try:\n            # Enhance query based on context type\n            if context_type == \"table\":\n                enhanced_query = f\"Search for table/financial data: {query}\"\n            elif context_type == \"ca_syllabus\":\n                enhanced_query = f\"CA syllabus question: {query}\"\n            else:\n                enhanced_query = query\n            \n            return self.get_embedding(enhanced_query)\n            \n        except Exception as e:\n            logger.error(f\"Failed to get query embedding: {e}\")\n            raise\n    \n    def cosine_similarity(self, embedding1: List[float], embedding2: List[float]) -> float:\n        \"\"\"Calculate cosine similarity between two embeddings\"\"\"\n        try:\n            # Convert to numpy arrays\n            vec1 = np.array(embedding1)\n            vec2 = np.array(embedding2)\n            \n            # Calculate cosine similarity\n            dot_product = np.dot(vec1, vec2)\n            norm1 = np.linalg.norm(vec1)\n            norm2 = np.linalg.norm(vec2)\n            \n            if norm1 == 0 or norm2 == 0:\n                return 0.0\n            \n            similarity = dot_product / (norm1 * norm2)\n            return float(similarity)\n            \n        except Exception as e:\n            logger.error(f\"Failed to calculate cosine similarity: {e}\")\n            return 0.0\n    \n    def create_enhanced_embedding_text(self, content: str, metadata: Dict[str, Any]) -> str:\n        \"\"\"Create enhanced text for embedding that includes metadata context\"\"\"\n        try:\n            # Build context from metadata\n            context_parts = []\n            \n            if metadata.get('level'):\n                context_parts.append(f\"CA {metadata['level']} level\")\n            if metadata.get('paper'):\n                context_parts.append(f\"Paper: {metadata['paper']}\")\n            if metadata.get('module'):\n                context_parts.append(f\"Module: {metadata['module']}\")\n            if metadata.get('chapter'):\n                context_parts.append(f\"Chapter: {metadata['chapter']}\")\n            if metadata.get('unit'):\n                context_parts.append(f\"Unit: {metadata['unit']}\")\n            \n            # Add content type context\n            content_type = metadata.get('content_type', 'text')\n            if content_type == 'table':\n                context_parts.append(\"Table/Financial Data\")\n            elif content_type == 'formula':\n                context_parts.append(\"Formula/Calculation\")\n            elif content_type == 'example':\n                context_parts.append(\"Example/Case Study\")\n            \n            context_text = \" | \".join(context_parts) if context_parts else \"\"\n            \n            # Combine context and content\n            if context_text:\n                enhanced_text = f\"Context: {context_text} | Content: {content}\"\n            else:\n                enhanced_text = content\n            \n            return enhanced_text\n            \n        except Exception as e:\n            logger.error(f\"Failed to create enhanced embedding text: {e}\")\n            return content\n\nclass EmbeddingManager:\n    def __init__(self):\n        self.azure_embeddings = AzureEmbeddings()\n    \n    def process_document_chunks(self, chunks: List[Dict[str, Any]], \n                              metadata: Dict[str, str]) -> List[Dict[str, Any]]:\n        \"\"\"Process document chunks and add embeddings\"\"\"\n        try:\n            processed_chunks = []\n            \n            # Prepare texts for batch embedding\n            texts_for_embedding = []\n            \n            for chunk in chunks:\n                # Create enhanced text with metadata context\n                enhanced_text = self.azure_embeddings.create_enhanced_embedding_text(\n                    chunk['content'], \n                    {**metadata, 'content_type': chunk.get('content_type', 'text')}\n                )\n                texts_for_embedding.append(enhanced_text)\n            \n            # Get embeddings in batch\n            logger.info(f\"Getting embeddings for {len(chunks)} document chunks...\")\n            embeddings = self.azure_embeddings.get_embeddings_batch(texts_for_embedding)\n            \n            # Combine chunks with embeddings\n            for i, chunk in enumerate(chunks):\n                processed_chunk = chunk.copy()\n                processed_chunk['embedding'] = embeddings[i]\n                processed_chunk['metadata'] = metadata\n                processed_chunks.append(processed_chunk)\n            \n            logger.info(f\"Successfully processed {len(processed_chunks)} chunks with embeddings\")\n            return processed_chunks\n            \n        except Exception as e:\n            logger.error(f\"Failed to process document chunks: {e}\")\n            raise\n    \n    def process_tables(self, tables: List[Dict[str, Any]], \n                      metadata: Dict[str, str]) -> List[Dict[str, Any]]:\n        \"\"\"Process tables and add embeddings\"\"\"\n        try:\n            from table_processor import TableProcessor\n            \n            table_processor = TableProcessor()\n            processed_tables = []\n            \n            # Prepare table texts for embedding\n            table_texts = []\n            \n            for table in tables:\n                # Create comprehensive table embedding text\n                table_embedding_text = table_processor.create_table_embedding_text(table, metadata)\n                table_texts.append(table_embedding_text)\n            \n            # Get embeddings for tables\n            logger.info(f\"Getting embeddings for {len(tables)} tables...\")\n            embeddings = self.azure_embeddings.get_embeddings_batch(table_texts)\n            \n            # Combine tables with embeddings\n            for i, table in enumerate(tables):\n                processed_table = table.copy()\n                processed_table['embedding'] = embeddings[i]\n                processed_table['metadata'] = metadata\n                processed_table['embedding_text'] = table_texts[i]\n                processed_tables.append(processed_table)\n            \n            logger.info(f\"Successfully processed {len(processed_tables)} tables with embeddings\")\n            return processed_tables\n            \n        except Exception as e:\n            logger.error(f\"Failed to process tables: {e}\")\n            raise\n    \n    def get_query_embedding_with_filters(self, query: str, level: str = None, \n                                       paper: str = None, content_type: str = \"general\") -> List[float]:\n        \"\"\"Get query embedding with context from filters\"\"\"\n        try:\n            # Enhance query with filter context\n            enhanced_parts = [query]\n            \n            if level:\n                enhanced_parts.append(f\"CA {level} level\")\n            if paper:\n                enhanced_parts.append(f\"Paper {paper}\")\n            \n            enhanced_query = \" \".join(enhanced_parts)\n            \n            return self.azure_embeddings.get_query_embedding(enhanced_query, content_type)\n            \n        except Exception as e:\n            logger.error(f\"Failed to get query embedding: {e}\")\n            raise\n","size_bytes":11071},"pdf_processor.py":{"content":"import fitz  # PyMuPDF\nimport pdfplumber\nimport pandas as pd\nfrom typing import List, Dict, Tuple, Any\nimport logging\nimport io\nimport base64\nimport tempfile\nimport os\nimport pytesseract\nimport cv2\nimport numpy as np\nfrom PIL import Image\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\ntry:\n    import camelot.io as camelot\n    CAMELOT_AVAILABLE = True\nexcept ImportError:\n    CAMELOT_AVAILABLE = False\n    logger.warning(\"Camelot not available - table extraction will use pdfplumber and tabula only\")\n    \ntry:\n    import tabula as tabula_py\n    TABULA_AVAILABLE = True\nexcept ImportError:\n    TABULA_AVAILABLE = False\n    logger.warning(\"Tabula not available - table extraction will use pdfplumber only\")\n\nclass PDFProcessor:\n    def __init__(self):\n        self.supported_formats = ['.pdf']\n    \n    def extract_text_and_tables(self, pdf_path: str) -> Dict[str, Any]:\n        \"\"\"\n        Comprehensive PDF processing to extract text, tables, and metadata\n        Returns structured data with text chunks and table data\n        \"\"\"\n        try:\n            results = {\n                'text_chunks': [],\n                'tables': [],\n                'metadata': {\n                    'total_pages': 0,\n                    'has_images': False,\n                    'has_tables': False,\n                    'processing_methods': []\n                }\n            }\n            \n            # Process with PyMuPDF for text and basic structure\n            pymupdf_results = self._process_with_pymupdf(pdf_path)\n            results['text_chunks'].extend(pymupdf_results['text_chunks'])\n            results['metadata']['total_pages'] = pymupdf_results['total_pages']\n            results['metadata']['has_images'] = pymupdf_results['has_images']\n            results['metadata']['processing_methods'].append('PyMuPDF')\n            \n            # Process with pdfplumber for enhanced table detection\n            pdfplumber_results = self._process_with_pdfplumber(pdf_path)\n            results['tables'].extend(pdfplumber_results['tables'])\n            if pdfplumber_results['tables']:\n                results['metadata']['has_tables'] = True\n                results['metadata']['processing_methods'].append('pdfplumber')\n            \n            # Process with camelot for robust table extraction (if available)\n            if CAMELOT_AVAILABLE:\n                camelot_results = self._process_with_camelot(pdf_path)\n                results['tables'].extend(camelot_results['tables'])\n                if camelot_results['tables']:\n                    results['metadata']['has_tables'] = True\n                    results['metadata']['processing_methods'].append('camelot')\n            \n            # Process with tabula for additional table extraction (if available)\n            if TABULA_AVAILABLE:\n                tabula_results = self._process_with_tabula(pdf_path)\n                results['tables'].extend(tabula_results['tables'])\n                if tabula_results['tables']:\n                    results['metadata']['has_tables'] = True\n                    results['metadata']['processing_methods'].append('tabula')\n            \n            # Process scanned pages with OCR if needed\n            ocr_results = self._process_with_ocr(pdf_path)\n            if ocr_results['text_chunks']:\n                results['text_chunks'].extend(ocr_results['text_chunks'])\n                results['metadata']['processing_methods'].append('OCR')\n            \n            # Deduplicate and merge tables\n            results['tables'] = self._deduplicate_tables(results['tables'])\n            \n            # Add table context to text chunks\n            results = self._add_table_context(results)\n            \n            logger.info(f\"PDF processing completed. Found {len(results['text_chunks'])} text chunks and {len(results['tables'])} tables\")\n            return results\n            \n        except Exception as e:\n            logger.error(f\"PDF processing failed: {e}\")\n            raise\n    \n    def _process_with_pymupdf(self, pdf_path: str) -> Dict[str, Any]:\n        \"\"\"Extract text and basic information using PyMuPDF\"\"\"\n        try:\n            doc = fitz.open(pdf_path)\n            text_chunks = []\n            has_images = False\n            \n            for page_num in range(len(doc)):\n                page = doc.load_page(page_num)\n                \n                # Extract text\n                text = page.get_text()\n                if text.strip():\n                    text_chunks.append({\n                        'content': text.strip(),\n                        'page_number': page_num + 1,\n                        'extraction_method': 'PyMuPDF',\n                        'content_type': 'text'\n                    })\n                \n                # Check for images\n                image_list = page.get_images()\n                if image_list:\n                    has_images = True\n            \n            total_pages = len(doc)\n            doc.close()\n            \n            return {\n                'text_chunks': text_chunks,\n                'total_pages': total_pages,\n                'has_images': has_images\n            }\n            \n        except Exception as e:\n            logger.error(f\"PyMuPDF processing failed: {e}\")\n            return {'text_chunks': [], 'total_pages': 0, 'has_images': False}\n    \n    def _process_with_pdfplumber(self, pdf_path: str) -> Dict[str, Any]:\n        \"\"\"Extract tables using pdfplumber\"\"\"\n        try:\n            tables = []\n            \n            with pdfplumber.open(pdf_path) as pdf:\n                for page_num, page in enumerate(pdf.pages):\n                    # Extract tables\n                    page_tables = page.extract_tables()\n                    \n                    for table_idx, table in enumerate(page_tables):\n                        if table and len(table) > 1:  # Ensure table has content\n                            # Convert to DataFrame\n                            # Clean column names and data\n                            columns = [str(col) if col is not None else f'col_{i}' for i, col in enumerate(table[0])]\n                            df = pd.DataFrame(table[1:], columns=columns)\n                            \n                            # Get context around table\n                            context_before, context_after = self._get_table_context(\n                                page, table, page_num + 1\n                            )\n                            \n                            # Replace NaN values with empty strings for JSON compatibility\n                            df = df.fillna('')\n                            \n                            table_data = {\n                                'data': df.to_dict('records'),\n                                'columns': list(df.columns),\n                                'html': df.to_html(index=False, classes='table table-striped'),\n                                'page_number': page_num + 1,\n                                'table_index': table_idx,\n                                'context_before': context_before,\n                                'context_after': context_after,\n                                'extraction_method': 'pdfplumber',\n                                'rows': len(df),\n                                'cols': len(df.columns)\n                            }\n                            \n                            tables.append(table_data)\n            \n            return {'tables': tables}\n            \n        except Exception as e:\n            logger.error(f\"pdfplumber processing failed: {e}\")\n            return {'tables': []}\n    \n    def _process_with_camelot(self, pdf_path: str) -> Dict[str, Any]:\n        \"\"\"Extract tables using camelot\"\"\"\n        if not CAMELOT_AVAILABLE:\n            return {'tables': []}\n        try:\n            tables = []\n            \n            # Use both lattice and stream methods\n            for method in ['lattice', 'stream']:\n                try:\n                    camelot_tables = camelot.read_pdf(pdf_path, flavor=method, pages='all')\n                    \n                    for table_idx, table in enumerate(camelot_tables):\n                        if table.accuracy > 50:  # Only use tables with good accuracy\n                            df = table.df\n                            \n                            # Clean the dataframe\n                            df = df.dropna(how='all').dropna(axis=1, how='all')\n                            \n                            if isinstance(df, pd.DataFrame) and not df.empty and len(df) > 1:\n                                # Replace NaN values with empty strings for JSON compatibility\n                                df = df.fillna('')\n                                \n                                table_data = {\n                                    'data': df.to_dict('records'),\n                                    'columns': list(df.columns),\n                                    'html': df.to_html(index=False, classes='table table-striped'),\n                                    'page_number': table.page,\n                                    'table_index': table_idx,\n                                    'extraction_method': f'camelot-{method}',\n                                    'accuracy': table.accuracy,\n                                    'rows': len(df),\n                                    'cols': len(df.columns),\n                                    'context_before': '',\n                                    'context_after': ''\n                                }\n                                \n                                tables.append(table_data)\n                                \n                except Exception as method_error:\n                    logger.warning(f\"Camelot {method} method failed: {method_error}\")\n                    continue\n            \n            return {'tables': tables}\n            \n        except Exception as e:\n            logger.error(f\"Camelot processing failed: {e}\")\n            return {'tables': []}\n    \n    def _process_with_tabula(self, pdf_path: str) -> Dict[str, Any]:\n        \"\"\"Extract tables using tabula\"\"\"\n        if not TABULA_AVAILABLE:\n            return {'tables': []}\n        try:\n            tables = []\n            \n            # Read all tables from PDF\n            tabula_tables = tabula_py.read_pdf(pdf_path, pages='all', multiple_tables=True)\n            \n            for table_idx, df in enumerate(tabula_tables):\n                if isinstance(df, pd.DataFrame) and not df.empty and len(df) > 1:\n                    # Clean the dataframe\n                    df = df.dropna(how='all').dropna(axis=1, how='all')\n                    \n                    if not df.empty:\n                        # Replace NaN values with empty strings for JSON compatibility\n                        df = df.fillna('')\n                        \n                        table_data = {\n                            'data': df.to_dict('records'),\n                            'columns': list(df.columns),\n                            'html': df.to_html(index=False, classes='table table-striped'),\n                            'page_number': 0,  # tabula doesn't provide page info easily\n                            'table_index': table_idx,\n                            'extraction_method': 'tabula',\n                            'rows': len(df),\n                            'cols': len(df.columns),\n                            'context_before': '',\n                            'context_after': ''\n                        }\n                        \n                        tables.append(table_data)\n            \n            return {'tables': tables}\n            \n        except Exception as e:\n            logger.error(f\"Tabula processing failed: {e}\")\n            return {'tables': []}\n    \n    def _process_with_ocr(self, pdf_path: str) -> Dict[str, Any]:\n        \"\"\"Process scanned pages with OCR\"\"\"\n        try:\n            text_chunks = []\n            doc = fitz.open(pdf_path)\n            \n            for page_num in range(len(doc)):\n                page = doc.load_page(page_num)\n                \n                # Check if page has extractable text\n                text = page.get_text().strip()\n                \n                # If no text or very little text, try OCR\n                if len(text) < 50:\n                    try:\n                        # Convert page to image\n                        pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))  # 2x zoom for better OCR\n                        img_data = pix.tobytes(\"png\")\n                        \n                        # Convert to PIL Image\n                        image = Image.open(io.BytesIO(img_data))\n                        \n                        # Preprocess image for better OCR\n                        image = self._preprocess_image_for_ocr(image)\n                        \n                        # Perform OCR\n                        ocr_text = pytesseract.image_to_string(image, lang='eng')\n                        \n                        if ocr_text.strip():\n                            text_chunks.append({\n                                'content': ocr_text.strip(),\n                                'page_number': page_num + 1,\n                                'extraction_method': 'OCR',\n                                'content_type': 'text_ocr'\n                            })\n                        \n                        # Try to extract tables from OCR text\n                        ocr_tables = self._extract_tables_from_ocr(image, page_num + 1)\n                        if ocr_tables:\n                            text_chunks.extend(ocr_tables)\n                            \n                    except Exception as ocr_error:\n                        logger.warning(f\"OCR failed for page {page_num + 1}: {ocr_error}\")\n                        continue\n            \n            doc.close()\n            return {'text_chunks': text_chunks}\n            \n        except Exception as e:\n            logger.error(f\"OCR processing failed: {e}\")\n            return {'text_chunks': []}\n    \n    def _preprocess_image_for_ocr(self, image: Image.Image) -> Image.Image:\n        \"\"\"Preprocess image for better OCR results\"\"\"\n        try:\n            # Convert PIL Image to OpenCV format\n            opencv_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)\n            \n            # Convert to grayscale\n            gray = cv2.cvtColor(opencv_image, cv2.COLOR_BGR2GRAY)\n            \n            # Apply Gaussian blur to reduce noise\n            blurred = cv2.GaussianBlur(gray, (1, 1), 0)\n            \n            # Apply threshold to get black and white image\n            _, thresh = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n            \n            # Convert back to PIL Image\n            processed_image = Image.fromarray(thresh)\n            \n            return processed_image\n            \n        except Exception as e:\n            logger.warning(f\"Image preprocessing failed: {e}\")\n            return image\n    \n    def _extract_tables_from_ocr(self, image: Image.Image, page_number: int) -> List[Dict]:\n        \"\"\"Extract table structure from OCR using image processing\"\"\"\n        try:\n            # This is a simplified table detection - in production, you might want\n            # to use more sophisticated methods like detecting table lines\n            \n            # Get OCR data with bounding boxes\n            ocr_data = pytesseract.image_to_data(image, output_type=pytesseract.Output.DICT)\n            \n            # Group text by lines (simplified table detection)\n            lines = {}\n            for i, text in enumerate(ocr_data['text']):\n                if text.strip():\n                    # Ensure coordinates are numeric\n                    try:\n                        y_coord = float(ocr_data['top'][i]) if ocr_data['top'][i] != '' else 0.0\n                        x_coord = float(ocr_data['left'][i]) if ocr_data['left'][i] != '' else 0.0\n                        confidence = float(ocr_data['conf'][i]) if ocr_data['conf'][i] != '' else 0.0\n                    except (ValueError, TypeError):\n                        continue  # Skip invalid coordinate data\n                        \n                    line_key = int(y_coord // 20)  # Group by approximate line\n                    \n                    if line_key not in lines:\n                        lines[line_key] = []\n                    \n                    lines[line_key].append({\n                        'text': text.strip(),\n                        'x': x_coord,\n                        'confidence': confidence\n                    })\n            \n            # If we have multiple lines with similar structure, it might be a table\n            if len(lines) > 2:\n                # Sort lines by y-coordinate (line_key is guaranteed to be int)\n                sorted_lines = sorted(lines.items(), key=lambda x: x[0])\n                \n                # Check if lines have similar number of elements (table-like structure)\n                line_lengths = [len(line[1]) for line in sorted_lines]\n                if line_lengths:  # Avoid division by zero\n                    avg_length = sum(line_lengths) / len(line_lengths)\n                    \n                    # If most lines have similar length, treat as table\n                    similar_length_lines = sum(1 for length in line_lengths if abs(length - avg_length) <= 2)\n                    \n                    if similar_length_lines / len(line_lengths) > 0.6:  # 60% of lines have similar length\n                        table_rows = []\n                        for _, line_data in sorted_lines:\n                            # Sort by x-coordinate (x is guaranteed to be float)\n                            sorted_cells = sorted(line_data, key=lambda cell: cell['x'])\n                            row = [cell['text'] for cell in sorted_cells if cell['text'].strip()]\n                            if row:  # Only add non-empty rows\n                                table_rows.append(row)\n                        \n                        if len(table_rows) > 1:\n                            return [{\n                                'content': f\"Table extracted from OCR:\\n{pd.DataFrame(table_rows[1:], columns=table_rows[0]).to_string()}\",\n                                'page_number': page_number,\n                                'extraction_method': 'OCR_table',\n                                'content_type': 'table_ocr'\n                            }]\n            \n            return []\n            \n        except Exception as e:\n            logger.warning(f\"OCR table extraction failed: {e}\")\n            return []\n    \n    def _get_table_context(self, page, table, page_number: int) -> Tuple[str, str]:\n        \"\"\"Get text context around a table\"\"\"\n        try:\n            # Get all text from the page\n            page_text = page.extract_text()\n            \n            # This is a simplified context extraction\n            # In a more sophisticated implementation, you would use the table's\n            # position to get text immediately before and after\n            \n            lines = page_text.split('\\n')\n            context_before = \"\"\n            context_after = \"\"\n            \n            # Get first few non-empty lines as context before\n            for line in lines[:10]:\n                if line.strip():\n                    context_before += line.strip() + \" \"\n                    if len(context_before) > 200:\n                        break\n            \n            # Get last few non-empty lines as context after\n            for line in lines[-10:]:\n                if line.strip():\n                    context_after += line.strip() + \" \"\n                    if len(context_after) > 200:\n                        break\n            \n            return context_before.strip(), context_after.strip()\n            \n        except Exception as e:\n            logger.warning(f\"Failed to get table context: {e}\")\n            return \"\", \"\"\n    \n    def _deduplicate_tables(self, tables: List[Dict]) -> List[Dict]:\n        \"\"\"Remove duplicate tables from different extraction methods\"\"\"\n        if not tables:\n            return []\n        \n        unique_tables = []\n        seen_signatures = set()\n        \n        for table in tables:\n            # Create a signature based on table dimensions and first few cells\n            signature = f\"{table['rows']}x{table['cols']}\"\n            \n            if 'data' in table and table['data']:\n                # Add first few cell values to signature\n                first_row = table['data'][0] if table['data'] else {}\n                # Filter out None values and convert all to strings for comparison\n                values = [str(v) for v in first_row.values() if v is not None]\n                if values:\n                    signature += str(sorted(values)[:3])\n            \n            if signature not in seen_signatures:\n                seen_signatures.add(signature)\n                unique_tables.append(table)\n        \n        logger.info(f\"Deduplicated {len(tables)} tables to {len(unique_tables)} unique tables\")\n        return unique_tables\n    \n    def _add_table_context(self, results: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Add table references to relevant text chunks\"\"\"\n        try:\n            # For each table, try to associate it with nearby text chunks\n            for table in results['tables']:\n                table_page = table['page_number']\n                \n                # Find text chunks from the same page or adjacent pages\n                relevant_chunks = [\n                    chunk for chunk in results['text_chunks']\n                    if abs(chunk['page_number'] - table_page) <= 1\n                ]\n                \n                # Add table reference to metadata of relevant chunks\n                for chunk in relevant_chunks:\n                    if 'table_references' not in chunk:\n                        chunk['table_references'] = []\n                    \n                    chunk['table_references'].append({\n                        'table_id': f\"table_{table_page}_{table['table_index']}\",\n                        'page_number': table_page,\n                        'extraction_method': table['extraction_method'],\n                        'rows': table['rows'],\n                        'cols': table['cols']\n                    })\n            \n            return results\n            \n        except Exception as e:\n            logger.warning(f\"Failed to add table context: {e}\")\n            return results\n","size_bytes":22612},"pyproject.toml":{"content":"[project]\nname = \"repl-nix-workspace\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nrequires-python = \">=3.11\"\ndependencies = [\n    \"appwrite>=13.0.0\",\n    \"camelot>=12.6.29\",\n    \"camelot-py>=1.0.9\",\n    \"fitz>=0.0.1.dev2\",\n    \"nltk>=3.9.1\",\n    \"numpy>=2.3.3\",\n    \"openai>=1.108.1\",\n    \"opencv-python>=4.11.0.86\",\n    \"pandas>=2.3.2\",\n    \"pdfplumber>=0.11.7\",\n    \"pillow>=11.3.0\",\n    \"psycopg2-binary>=2.9.10\",\n    \"pymupdf>=1.26.4\",\n    \"pytesseract>=0.3.13\",\n    \"requests>=2.32.5\",\n    \"scikit-learn>=1.7.2\",\n    \"streamlit>=1.49.1\",\n    \"tabula>=1.0.5\",\n    \"tabula-py>=2.10.0\",\n]\n\n[[tool.uv.index]]\nexplicit = true\nname = \"pytorch-cpu\"\nurl = \"https://download.pytorch.org/whl/cpu\"\n\n[tool.uv.sources]\nAA-module = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nABlooper = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nAnalysisG = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nAutoRAG = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nBERTeam = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nBxTorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nByaldi = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nCALM-Pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nCOPEX-high-rate-compression-quality-metrics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nCityLearn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nCoCa-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nCoLT5-attention = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nComfyUI-EasyNodes = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nCrawl4AI = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nDALL-E = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nDI-toolkit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nDatasetRising = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nDeepCache = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nDeepMatter = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nDraugr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nESRNN = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nEn-transformer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nExpoSeq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nFLAML = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nFSRS-Optimizer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nGANDLF = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nGQLAlchemy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nGhostScan = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nGraKeL = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nHEBO = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nIOPaint = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nISLP = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nInvokeAI = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nJAEN = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nKapoorLabs-Lightning = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nLightAutoML = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nLingerGRN = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nMMEdu = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nMRzeroCore = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nModeva = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nNeuralFoil = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nNiMARE = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nNinjaTools = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nOpenHosta = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nOpenNMT-py = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nPOT = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nPVNet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nPaLM-rlhf-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nPepperPepper = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nPiML = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nPoutyne = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nQNCP = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nRAGatouille = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nRareGO = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nRealtimeSTT = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nRelevanceAI-Workflows-Core = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nResemblyzer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nScandEval = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nSimba-UW-tf-dev = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nSwissArmyTransformer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nTPOT = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nTTS = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nTorchCRF = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nTotalSegmentator = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nUtilsRL = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nWhisperSpeech = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nXAISuite = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\na-unet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\na5dev = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naccelerate = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naccelerated-scan = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naccern-xyme = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nachatbot = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nacids-rave = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nactorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nacvl-utils = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nadabelief-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nadam-atan2-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nadan-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nadapters = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nadmin-torch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nadtoolbox = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nadversarial-robustness-toolbox = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naeiou = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naeon = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nafricanwhisper = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nag-llama-api = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nagentdojo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nagilerl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nai-edge-torch-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nai-parrot = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nai-python = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nai-transform = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nai2-olmo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nai2-olmo-core = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nai2-tango = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naicmder = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naider-chat = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naider-chat-x = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naif360 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naihwkit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naimodelshare = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nairllm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nairtestProject = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nairunner = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naisak = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naislib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naisquared = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naistore = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naithree = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nakasha-terminal = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nalibi = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nalibi-detect = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nalignn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nall-clip = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nallennlp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nallennlp-models = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nallennlp-pvt-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nallophant = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nallosaurus = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naloy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nalpaca-eval = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nalphafold2-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nalphafold3-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nalphamed-federated = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nalphawave = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\namazon-braket-pennylane-plugin = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\namazon-photos = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nanemoi-graphs = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nanemoi-models = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nanomalib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\napache-beam = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\napache-tvm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naperturedb = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naphrodite-engine = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naqlm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\narcAGI2024 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\narchisound = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nargbind = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\narize = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\narm-pytorch-utilities = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\narray-api-compat = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\narus = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nassert-llm-tools = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nasteroid = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nasteroid-filterbanks = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nastra-llm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nastrovision = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\natomate2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nattacut = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naudio-diffusion-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naudio-encoders-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naudio-separator = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naudiocraft = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naudiolm-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nauralis = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nauraloss = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nauto-gptq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nautoawq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nautoawq-kernels = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\n\"autogluon.multimodal\" = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\n\"autogluon.tabular\" = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\n\"autogluon.timeseries\" = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nautotrain-advanced = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\navdeepfake1m = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\naws-fortuna = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nax-platform = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nazureml-automl-dnn-vision = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nazureml-contrib-automl-dnn-forecasting = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nazureml-evaluate-mlflow = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nazureml-metrics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nazureml-train-automl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nb2bTools = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbackpack-for-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbalrog-nle = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbatch-face = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbatchalign = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbatchgeneratorsv2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbatchtensor = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbbrl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbenchpots = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbent = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbert-score = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbertopic = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbertviz = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbestOf = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbetty-ml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbig-sleep = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbigdl-core-cpp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbigdl-core-npu = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbigdl-llm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbigdl-nano = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\n\"bioimageio.core\" = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbitfount = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbitsandbytes = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbittensor = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbittensor-cli = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nblackboxopt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nblanc = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nblindai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbm25-pt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nboltz = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbotorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nboxmot = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbrainchain = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbraindecode = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbrevitas = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbriton = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbrowsergym-visualwebarena = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbuzz-captions = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbyotrack = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nbyzerllm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nc4v-py = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncalflops = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncame-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncamel-ai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncamel-tools = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncannai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncaptum = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncarte-ai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncarvekit-colab = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncatalyst = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncausalml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncausalnex = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncausy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncbrkit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncca-zoo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncdp-backend = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncellacdc = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncellfinder = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncellpose = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncellxgene-census = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nchattts = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nchemprop = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nchgnet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nchitra = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncircuitsvis = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncjm-yolox-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclarinpl-embeddings = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclass-resolver = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclassifier-free-guidance-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclassiq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclassy-core = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclean-fid = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncleanvision = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclip-anytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclip-benchmark = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclip-by-openai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclip-interrogator = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclip-retrieval = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncltk = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclu = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nclusterops = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncnocr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncnstd = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncoba = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncofi = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncolbert-ai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncolpali-engine = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncompel = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncomposabl-ray = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncomposabl-ray-dev = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncomposabl-train = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncomposabl-train-dev = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncomposer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncompressai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncompressed-tensors = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncompressed-tensors-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nconcrete-python = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nconfit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nconformer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncontextualSpellCheck = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncontinual-inference = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncontrolnet-aux = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nconvokit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncoola = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncoqui-tts = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncoqui-tts-trainer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncraft-text-detector = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncreme = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncrocodile = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncrowd-kit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncryoSPHERE = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncsle-common = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncsle-system-identification = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nctgan = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncurated-transformers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncut-cross-entropy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncvat-sdk = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ncybertask = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nd3rlpy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndalle-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndalle2-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndanila-lib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndanling = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndarts = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndarwin-py = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndata-gradients = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndatachain = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndataclass-array = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndataeval = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndatarobot-drum = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndatarobotx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndatasets = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndatumaro = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndctorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeep-utils = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepchecks = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepchem = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepctr-torch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepecho = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepepochs = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepforest = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeeplabcut = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepmd-kit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepmultilingualpunctuation = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepparse = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeeprobust = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepsparse = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepsparse-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndeepspeed = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndenoising-diffusion-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndescript-audio-codec = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndescript-audiotools = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndetecto = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndetoxify = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndgenerate = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndghs-imgutils = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndgl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndialogy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndice-ml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndiffgram = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndiffq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndiffusers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndistilabel = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndistrifuser = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndnikit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndocarray = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndoclayout-yolo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndocling-ibm-models = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndocquery = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndomino-code-assist = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndreamsim = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndropblock = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndruida = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ndvclive = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ne2-tts-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ne2cnn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ne3nn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\neasyocr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nebtorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\necallisto-ng = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nedsnlp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\neffdet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\neinx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\neir-dl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\neis1600 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\neland = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nema-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nembedchain = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nenformer-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nentmax = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nesm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nespaloma-charge = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nespnet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\netils = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\netna = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nevadb = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nevalscope = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nevaluate = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nexllamav2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nextractable = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nface-alignment = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfacenet-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfacexlib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfair-esm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfairseq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfairseq2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfairseq2n = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfaker-file = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfarm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfast-bert = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfast-pytorch-kmeans = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfastai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfastcore = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfastestimator-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfasttreeshap = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfedml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfelupe = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfemr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfft-conv-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfickling = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfireworks-ai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nflair = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nflashrag-dev = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nflax = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nflexgen = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nflgo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nflopth = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nflowcept = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nflytekitplugins-kfpytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nflytekitplugins-onnxpytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfmbench = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfocal-frequency-loss = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfoldedtensor = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfractal-tasks-core = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfreegenius = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfreqtrade = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfschat = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfunasr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfunctorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfunlbm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nfunsor = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngalore-torch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngarak = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngarf = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngateloop-transformer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngeffnet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngenutility = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngfpgan = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngigagan-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngin-config = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nglasflow = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngliner = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngluonts = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngmft = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngoogle-cloud-aiplatform = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngpforecaster = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngpt3discord = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngpytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngrad-cam = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngraph-weather = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngraphistry = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngravitorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngretel-synthetics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngsplat = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nguardrails-ai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nguidance = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ngymnasium = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhanlp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhappytransformer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhbutils = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nheavyball = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhezar = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhf-deepali = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhf-doc-builder = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhigher = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhjxdl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhkkang-utils = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhordelib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhpsv2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhuggingface-hub = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhummingbird-ml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhvae-backbone = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhya = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nhypothesis-torch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nibm-metrics-plugin = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nibm-watson-machine-learning = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nibm-watsonx-ai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nicetk = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nicevision = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\niden = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nidvpackage = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\niglovikov-helper-functions = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nimagededup = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nimagen-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nimaginAIry = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nimg2vec-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nincendio = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninference = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninference-gpu = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninfinity-emb = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninfo-nce-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninfoapps-mlops-sdk = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninstructlab = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninstructlab-dolomite = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninstructlab-eval = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninstructlab-sdg = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninstructlab-training = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ninvisible-watermark = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\niobm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nipex-llm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\niree-turbine = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nirisml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nirisml-tasks-azure-openai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nirisml-tasks-torchvision = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nirisml-tasks-training = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nitem-matching = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nivadomed = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\njaqpotpy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\njina = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\njudo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\njunky = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nk-diffusion = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nk1lib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nk2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkappadata = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkappamodules = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkarbonn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkats = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkbnf = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkedro-datasets = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkeybert = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkeytotext = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkhoj = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkiui = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkonfuzio-sdk = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkornia = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkornia-moons = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkraken = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkwarray = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nkwimage = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlabml-nn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlagent = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlaion-clap = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlale = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlama-cleaner = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlancedb = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlangcheck = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlangkit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlangroid = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlangtest = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlayoutparser = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nldp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nleafmap = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nleap-ie = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nleibniz = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nleptonai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nletmedoit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlhotse = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlib310 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlibpecos = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlibrec-auto = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlibretranslate = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nliger-kernel = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nliger-kernel-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlightning = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlightning-bolts = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlightning-fabric = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlightning-habana = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlightning-lite = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlightrag = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlightweight-gan = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlightwood = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlinear-attention-transformer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlinear-operator = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlinformer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlinformer-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nliom-toolkit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlion-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlit-nlp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlitdata = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlitelama = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlitgpt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllama-index-embeddings-adapter = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllama-index-embeddings-clip = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllama-index-embeddings-instructor = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllama-index-llms-huggingface = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllama-index-postprocessor-colbert-rerank = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllm-blender = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllm-foundry = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllm-guard = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllm-rs = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllm2vec = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllmcompressor = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllmlingua = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nllmvm-cli = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlm-eval = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlmdeploy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlmms-eval = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlocal-attention = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlovely-tensors = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlpips = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nlycoris-lora = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmace-torch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmagic-pdf = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmagicsoup = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmagvit2-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmaite = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmanga-ocr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmanifest-ml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmanipulation = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmarker-pdf = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmatgl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmed-imagetools = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmedaka = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmedcat = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmedmnist = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmegablocks = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmegatron-energon = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmemos = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmeshgpt-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmetatensor-torch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmflux = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmia-vgg = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmiditok = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nminari = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nminicons = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nml2rt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmlagents = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmlbench-core = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmlcroissant = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmlpfile = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmlx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmlx-whisper = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmmaction2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmmengine = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmmengine-lite = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmmocr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmmpose = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmmsegmentation = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmodeci-mdf = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmodel2vec = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmodelscope = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmodelspec = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmonai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmonai-weekly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmonotonic-alignment-search = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmonty = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmosaicml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmosaicml-streaming = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmoshi = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmteb = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmtmtrain = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmulti-quantization = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nmyhand = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnGPT-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnaeural-core = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnapari = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnapatrackmater = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnara-wpe = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnatten = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnbeats-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnebulae = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnemo-toolkit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nneptune = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nneptune-client = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnerfacc = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnerfstudio = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnessai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnetcal = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nneural-rag = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nneuralforecast = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nneuralnets = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nneuralprophet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nneuspell = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnevergrad = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnexfort = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnimblephysics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnirtorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnkululeko = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnlp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnlptooltest = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnnAudio = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnnodely = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnnsight = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnnunetv2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnoisereduce = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnonebot-plugin-nailongremove = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnowcasting-dataloader = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnowcasting-forecast = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnshtrainer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnuwa-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnvflare = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nnvidia-modelopt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nocf-datapipes = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nocnn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nogb = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nohmeow-blurr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nolive-ai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nomlt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nommlx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nonediff = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nonediffx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nonnx2pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nonnx2torch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopacus = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopen-clip-torch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopen-flamingo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopen-interpreter = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopenbb-terminal-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopenmim = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopenparse = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopenunmix = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopenvino-dev = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopenvino-tokenizers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopenvino-xai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopenwakeword = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nopt-einsum-fx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noptimum = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noptimum-habana = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noptimum-intel = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noptimum-neuron = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noptimum-quanto = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noptree = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noptuna = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noptuna-dashboard = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noptuna-integration = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noracle-ads = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\norbit-ml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\notx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noutetts = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noutlines = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\noutlines-core = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npaddlenlp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npai-easycv = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npandasai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npanns-inference = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npatchwork-cli = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npeft = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npegasuspy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npelutils = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npenn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nperforatedai-freemium = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nperformer-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npetastorm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npfio = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npgmpy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nphenolrs = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nphobos = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npi-zero-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npinecone-text = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npiq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npix2tex = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npix2text = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npnnx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npolicyengine-us-data = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npolyfuzz = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npomegranate = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npositional-encodings = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nprefigure = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nproduct-key-memory = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nptflops = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nptwt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npulser-core = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npunctuators = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npy2ls = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyabsa = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\n\"pyannote.audio\" = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyawd = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyclarity = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npycox = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyfemtet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyg-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npygrinder = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyhealth = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyhf = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyiqa = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npykeen = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npykeops = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npylance = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npylineaGT = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npymanopt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npymde = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npypots = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyqlib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyqtorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyro-ppl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npysentimiento = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyserini = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npysr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npythainlp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npython-doctr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-fid = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-forecasting = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-ignite = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-kinematics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-lightning = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-lightning-bolts = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-metric-learning = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-model-summary = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-msssim = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-pfn-extras = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-pretrained-bert = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-ranger = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-seed = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-tabnet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-tabular = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-toolbelt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-transformers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-transformers-pvt-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-triton-rocm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-warmup = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch-wavelets = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch_optimizer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorch_revgrad = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorchcv = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npytorchltr2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyvene = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\npyvespa = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nqianfan = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nqibo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nqiskit-machine-learning = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nqtorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nquanto = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nquick-anomaly-detector = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrastervision = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrastervision-pytorch-backend = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrastervision-pytorch-learner = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nray-lightning = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrclip = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrealesrgan = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrecbole = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrecommenders = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nredcat = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nreformer-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nregex-sampler = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nreplay-rec = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrerankers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nresearch-framework = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nresemble-enhance = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nresnest = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrf-clip = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrf-groundingdino = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrfconv = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrich-logger = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nring-attention-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrltrade-test = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrotary-embedding-torch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrsp-ml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nrust-circuit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ns2fft = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ns3prl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ns3torchconnector = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsaferx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsafetensors = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsagemaker-huggingface-inference-toolkit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsagemaker-ssh-helper = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsalesforce-lavis = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsalesforce-merlion = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsamv2 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nscib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nscib-metrics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nscvi-tools = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsdmetrics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsecretflow = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsegment-anything-hq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsegment-anything-py = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsegmentation-models-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nself-rewarding-lm-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsemantic-kernel = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsemantic-router = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsenselab = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsent2vec = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsentence-transformers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsequence-model-train = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nserotiny = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsevenn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsglang = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nshap = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsilero-api-server = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsilero-vad = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsilicondiff-npu = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsimclr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsimple-lama-inpainting = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsinabs = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsixdrepnet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nskforecast = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nskorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nskrl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nskt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsktime = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsktmls = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nslangtorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsmartnoise-synth = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsmashed = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsmplx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsmqtk-descriptors = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsmqtk-detection = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsnntorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsnorkel = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsnowflake-ml-python = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nso-vits-svc-fork = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsonusai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsony-custom-layers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsotopia = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspacr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspacy-curated-transformers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspacy-experimental = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspacy-huggingface-pipelines = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspacy-llm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspacy-transformers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspan-marker = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspandrel = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspandrel-extra-arches = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsparrow-python = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspatialdata = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspeechbrain = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspeechtokenizer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspikeinterface = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspikingjelly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspotiflow = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspotpython = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nspotriver = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsquirrel-core = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstable-baselines3 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstable-diffusion-sdkit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstable-ts = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstanford-stk = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstanfordnlp = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstanza = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstartorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstreamtasks = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstruct-eqtable = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nstylegan2-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsupar = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsuper-gradients = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsuper-image = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsuperlinked = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsupervisely = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsurya-ocr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsvdiff-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nswarm-models = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nswarmauri = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nswarms-memory = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nswebench = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsyft = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsympytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsyne-tune = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nsynthcity = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nt5 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntab-transformer-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntabpfn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntaming-transformers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntaming-transformers-rom1504 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntaskwiz = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntbparse = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntecton = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntensor-parallel = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntensorcircuit-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntensordict = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntensordict-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntensorizer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntensorrt-llm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntexify = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntext2text = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntextattack = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntfkit = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nthepipe-api = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nthinc = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nthingsvision = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nthirdai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nthop = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntianshou = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntidy3d = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntimesfm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntimm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntipo-kgen = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntmnt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntoad = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntomesd = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntop2vec = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-audiomentations = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-dct = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-delaunay = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-directml = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-ema = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-encoding = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-fidelity = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-geometric = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-geopooling = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-harmonics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-kmeans = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-lr-finder = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-max-mem = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-npu = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-optimi = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-optimizer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-ort = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-pitch-shift = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-ppr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-pruning = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-snippets = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-stoi = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-struct = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorch-tensorrt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchani = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchattacks = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchaudio = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchbiggraph = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchcam = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchcde = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchcfm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchcrepe = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchdata = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchdatasets-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchdiffeq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchdyn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchestra = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorcheval = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorcheval-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchextractor = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchfcpe = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchfun = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchfunc-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchgeo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchgeometry = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchio = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchjpeg = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchlayers-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchmeta = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchmetrics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchmocks = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchpack = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchpippy = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchpq = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchprofile = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchquantlib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchrec = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchrec-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchrec-nightly-cpu = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchrl = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchrl-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchscale = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchsde = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchseg = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchserve = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchserve-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchsnapshot-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchsr = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchstain = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchsummaryX = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchtext = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchtnt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchtnt-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchtyping = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchutil = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchvinecopulib = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchvision = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchviz = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchx-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntorchxrayvision = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntotalspineseg = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntracebloc-package-dev = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntrainer = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntransformer-engine = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntransformer-lens = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntransformer-smaller-training-vocab = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntransformers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntransformers-domain-adaptation = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntransfusion-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntransparent-background = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntreescope = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntrolo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntsai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntslearn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nttspod = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntxtai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\ntyro = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nu8darts = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nuhg = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nuitestrunner-syberos = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nultimate-rvc = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nultralytics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nultralytics-thop = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunav = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunbabel-comet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunderthesea = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunfoldNd = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunimernet = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunitorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunitxt = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunsloth = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunsloth-zoo = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunstructured = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nunstructured-inference = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nutilsd = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nv-diffusion-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvIQA = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvectice = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvector-quantize-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvectorhub-nightly = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nversatile-audio-upscaler = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvertexai = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvesin = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvgg-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvideo-representations-extractor = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nviser = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvision-datasets = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvisionmetrics = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvisu3d = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvit-pytorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nviturka-nn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvllm = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvllm-flash-attn = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvocos = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvollseg = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nvtorch = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nwavmark = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nwdoc = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nwhisper-live = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nwhisper-timestamped = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nwhisperx = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nwilds = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nwordllama = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nworker-automate-hub = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nwxbtool = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nx-clip = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nx-transformers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nxaitk_saliency = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nxformers = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nxgrammar = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nxinference = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nxtts-api-server = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nyolo-poser = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nyolov5 = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nyolov7-package = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nyta-general-utils = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nzensvi = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nzetascale = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\nzuko = [{ index = \"pytorch-cpu\", marker = \"platform_system == 'Linux'\" }]\n","size_bytes":90987},"rag_pipeline.py":{"content":"from openai import AzureOpenAI\nfrom typing import List, Dict, Any, Tuple\nimport logging\nfrom database import VectorDatabase\nfrom embeddings import EmbeddingManager\nfrom config import AZURE_OPENAI_ENDPOINT, AZURE_OPENAI_KEY, AZURE_OPENAI_VERSION, AZURE_LLM_DEPLOYMENT\nimport json\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nclass RAGPipeline:\n    def __init__(self):\n        # Configure Azure OpenAI client for LLM\n        self.client = AzureOpenAI(\n            azure_endpoint=AZURE_OPENAI_ENDPOINT,\n            api_key=AZURE_OPENAI_KEY,\n            api_version=AZURE_OPENAI_VERSION\n        )\n        \n        self.llm_deployment = AZURE_LLM_DEPLOYMENT\n        self.vector_db = VectorDatabase()\n        self.embedding_manager = EmbeddingManager()\n        \n        # RAG configuration\n        self.top_k_documents = 5\n        self.top_k_tables = 3\n        self.similarity_threshold = 0.5\n        \n    def answer_question(self, question: str, level: str = None, paper: str = None,\n                       module: str = None, chapter: str = None, unit: str = None,\n                       include_tables: bool = True) -> Dict[str, Any]:\n        \"\"\"\n        Answer a question using RAG pipeline with table-aware retrieval\n        \"\"\"\n        try:\n            logger.info(f\"Processing question: {question}\")\n            \n            # Step 1: Generate query embedding\n            query_embedding = self.embedding_manager.get_query_embedding_with_filters(\n                question, level or '', paper or ''\n            )\n            \n            # Step 2: Retrieve relevant documents\n            document_results = self.vector_db.similarity_search_documents(\n                query_embedding=query_embedding,\n                top_k=self.top_k_documents,\n                level=level,\n                paper=paper,\n                module=module,\n                chapter=chapter,\n                unit=unit\n            )\n            \n            # Step 3: Retrieve relevant tables if requested\n            table_results = []\n            if include_tables:\n                table_results = self.vector_db.similarity_search_tables(\n                    query_embedding=query_embedding,\n                    top_k=self.top_k_tables,\n                    level=level,\n                    paper=paper,\n                    module=module,\n                    chapter=chapter,\n                    unit=unit\n                )\n            \n            # Step 4: Filter by similarity threshold\n            filtered_documents = [\n                doc for doc in document_results \n                if doc['similarity'] >= self.similarity_threshold\n            ]\n            \n            filtered_tables = [\n                table for table in table_results \n                if table['similarity'] >= self.similarity_threshold\n            ]\n            \n            # Step 5: Handle empty results gracefully\n            if not filtered_documents and not filtered_tables:\n                return {\n                    'answer': f\"I don't have any relevant information about '{question}' in my knowledge base yet. Please upload some CA study materials first, or try a more general question about accounting principles.\",\n                    'confidence': 0.0,\n                    'sources': {'documents': [], 'tables': []},\n                    'metadata': {\n                        'level': level,\n                        'paper': paper,\n                        'module': module,\n                        'chapter': chapter,\n                        'unit': unit,\n                        'documents_found': 0,\n                        'tables_found': 0,\n                        'processing_time': 0\n                    },\n                    'suggestions': self._generate_suggestions(question, level, paper)\n                }\n            \n            # Step 6: Prepare context for LLM\n            context = self._prepare_context(filtered_documents, filtered_tables)\n            \n            # Step 7: Generate answer using LLM\n            answer_data = self._generate_answer(question, context, level, paper)\n            \n            # Step 7: Prepare response with citations\n            response = {\n                'answer': answer_data['answer'],\n                'confidence': self._calculate_confidence(filtered_documents, filtered_tables),\n                'sources': {\n                    'documents': [self._format_document_source(doc) for doc in filtered_documents[:3]],\n                    'tables': [self._format_table_source(table) for table in filtered_tables[:2]]\n                },\n                'metadata': {\n                    'level': level,\n                    'paper': paper,\n                    'module': module,\n                    'chapter': chapter,\n                    'unit': unit,\n                    'documents_found': len(filtered_documents),\n                    'tables_found': len(filtered_tables),\n                    'processing_time': answer_data.get('processing_time', 0)\n                },\n                'suggestions': self._generate_suggestions(question, level, paper)\n            }\n            \n            logger.info(f\"Question answered successfully with {len(filtered_documents)} documents and {len(filtered_tables)} tables\")\n            return response\n            \n        except Exception as e:\n            logger.error(f\"Failed to answer question: {e}\")\n            return {\n                'answer': \"I apologize, but I encountered an error while processing your question. Please try again or rephrase your question.\",\n                'confidence': 0.0,\n                'sources': {'documents': [], 'tables': []},\n                'metadata': {'error': str(e)},\n                'suggestions': []\n            }\n    \n    def _prepare_context(self, documents: List[Dict], tables: List[Dict]) -> str:\n        \"\"\"Prepare context from retrieved documents and tables\"\"\"\n        try:\n            context_parts = []\n            \n            # Add document context\n            if documents:\n                context_parts.append(\"=== RELEVANT CONTENT ===\")\n                for i, doc in enumerate(documents[:5]):  # Limit to top 5\n                    context_parts.append(f\"Document {i+1} (Similarity: {doc['similarity']:.2f}):\")\n                    context_parts.append(f\"Source: {doc['file_name']}\")\n                    if doc.get('level'):\n                        context_parts.append(f\"Level: {doc['level']}, Paper: {doc['paper']}\")\n                    if doc.get('chapter'):\n                        context_parts.append(f\"Chapter: {doc['chapter']}\")\n                    context_parts.append(f\"Content: {doc['content']}\")\n                    context_parts.append(\"---\")\n            \n            # Add table context\n            if tables:\n                context_parts.append(\"=== RELEVANT TABLES ===\")\n                for i, table in enumerate(tables[:3]):  # Limit to top 3\n                    context_parts.append(f\"Table {i+1} (Similarity: {table['similarity']:.2f}):\")\n                    context_parts.append(f\"Source: {table['file_name']}, Page: {table['page_number']}\")\n                    if table.get('level'):\n                        context_parts.append(f\"Level: {table['level']}, Paper: {table['paper']}\")\n                    \n                    # Add table data\n                    if table.get('table_html'):\n                        context_parts.append(\"Table HTML:\")\n                        context_parts.append(table['table_html'][:1000])  # Limit HTML length\n                    \n                    if table.get('context_before'):\n                        context_parts.append(f\"Context before table: {table['context_before']}\")\n                    if table.get('context_after'):\n                        context_parts.append(f\"Context after table: {table['context_after']}\")\n                    \n                    context_parts.append(\"---\")\n            \n            return \"\\n\".join(context_parts)\n            \n        except Exception as e:\n            logger.error(f\"Failed to prepare context: {e}\")\n            return \"No relevant context found.\"\n    \n    def _generate_answer(self, question: str, context: str, level: str = None, \n                        paper: str = None) -> Dict[str, Any]:\n        \"\"\"Generate answer using Azure OpenAI LLM\"\"\"\n        try:\n            import time\n            start_time = time.time()\n            \n            # Prepare system message based on CA context\n            system_message = self._get_system_message(level, paper)\n            \n            # Prepare user message\n            user_message = f\"\"\"\nQuestion: {question}\n\nContext:\n{context}\n\nInstructions:\n1. Answer the question based on the provided context\n2. If the context includes tables, reference specific data points\n3. Provide explanations for financial calculations or formulas\n4. Include references to relevant standards, sections, or regulations\n5. If the answer involves numerical data from tables, be precise\n6. If you cannot answer based on the context, say so clearly\n7. For CA-specific topics, use appropriate terminology and concepts\n8. Structure your answer clearly with headings if needed\n\"\"\"\n            \n            response = self.client.chat.completions.create(\n                model=self.llm_deployment,\n                messages=[\n                    {\"role\": \"system\", \"content\": system_message},\n                    {\"role\": \"user\", \"content\": user_message}\n                ],\n                max_tokens=2000,\n                temperature=0.3  # Lower temperature for more factual responses\n            )\n            \n            answer = response.choices[0].message.content.strip()\n            processing_time = time.time() - start_time\n            \n            return {\n                'answer': answer,\n                'processing_time': processing_time\n            }\n            \n        except Exception as e:\n            logger.error(f\"Failed to generate answer: {e}\")\n            return {\n                'answer': \"I apologize, but I encountered an error while generating the answer. Please try again.\",\n                'processing_time': 0\n            }\n    \n    def _get_system_message(self, level: str = None, paper: str = None) -> str:\n        \"\"\"Get system message based on CA level and paper\"\"\"\n        base_message = \"\"\"You are an expert CA (Chartered Accountancy) assistant specializing in helping Indian CA students with their studies. You have deep knowledge of:\n\n- Indian Accounting Standards (Ind AS)\n- Companies Act 2013\n- Income Tax Act 1961\n- GST regulations\n- Auditing and Assurance Standards\n- Financial Management and Economics\n- Strategic Management\n- Ethics and Corporate Governance\n\nYour responses should be:\n- Accurate and based on current Indian standards and regulations\n- Educational and helpful for students\n- Well-structured with clear explanations\n- Include practical examples when relevant\n- Reference specific standards or sections when applicable\n- Focused on helping students understand concepts deeply\"\"\"\n        \n        if level:\n            level_specific = f\"\\n\\nYou are currently helping a student at the CA {level} level.\"\n            \n            if level == \"Foundation\":\n                level_specific += \" Focus on fundamental concepts, basic principles, and foundational knowledge.\"\n            elif level == \"Intermediate\":\n                level_specific += \" Provide intermediate-level explanations with moderate complexity and practical applications.\"\n            elif level == \"Final\":\n                level_specific += \" Deliver advanced, comprehensive explanations suitable for final-level CA students.\"\n            \n            base_message += level_specific\n        \n        if paper:\n            base_message += f\"\\n\\nThe question relates to {paper}. Tailor your response to this specific paper's syllabus and requirements.\"\n        \n        return base_message\n    \n    def _calculate_confidence(self, documents: List[Dict], tables: List[Dict]) -> float:\n        \"\"\"Calculate confidence score based on retrieval results\"\"\"\n        try:\n            if not documents and not tables:\n                return 0.0\n            \n            # Calculate average similarity\n            doc_similarities = [doc['similarity'] for doc in documents]\n            table_similarities = [table['similarity'] for table in tables]\n            \n            all_similarities = doc_similarities + table_similarities\n            \n            if not all_similarities:\n                return 0.0\n            \n            avg_similarity = sum(all_similarities) / len(all_similarities)\n            \n            # Boost confidence if we have both documents and tables\n            if documents and tables:\n                avg_similarity *= 1.1\n            \n            # Cap at 1.0\n            return min(avg_similarity, 1.0)\n            \n        except Exception as e:\n            logger.error(f\"Failed to calculate confidence: {e}\")\n            return 0.5\n    \n    def _format_document_source(self, doc: Dict) -> Dict[str, Any]:\n        \"\"\"Format document source for response\"\"\"\n        return {\n            'file_name': doc['file_name'],\n            'level': doc.get('level', ''),\n            'paper': doc.get('paper', ''),\n            'chapter': doc.get('chapter', ''),\n            'similarity': round(doc['similarity'], 2),\n            'snippet': doc['content'][:200] + \"...\" if len(doc['content']) > 200 else doc['content']\n        }\n    \n    def _format_table_source(self, table: Dict) -> Dict[str, Any]:\n        \"\"\"Format table source for response\"\"\"\n        return {\n            'file_name': table['file_name'],\n            'page_number': table['page_number'],\n            'level': table.get('level', ''),\n            'paper': table.get('paper', ''),\n            'chapter': table.get('chapter', ''),\n            'similarity': round(table['similarity'], 2),\n            'rows': table.get('rows', 0),\n            'cols': table.get('cols', 0),\n            'context': table.get('context_before', '')[:100] + \"...\" if table.get('context_before') else \"\"\n        }\n    \n    def _generate_suggestions(self, question: str, level: str = None, \n                            paper: str = None) -> List[str]:\n        \"\"\"Generate related question suggestions\"\"\"\n        try:\n            suggestions = []\n            \n            # Basic suggestions based on question type\n            question_lower = question.lower()\n            \n            if 'balance sheet' in question_lower:\n                suggestions.extend([\n                    \"What are the components of a balance sheet?\",\n                    \"How to prepare a balance sheet as per Schedule III?\",\n                    \"Explain the classification of assets and liabilities\"\n                ])\n            \n            elif 'profit' in question_lower or 'income' in question_lower:\n                suggestions.extend([\n                    \"How to prepare Statement of Profit and Loss?\",\n                    \"What are the components of comprehensive income?\",\n                    \"Explain revenue recognition principles\"\n                ])\n            \n            elif 'tax' in question_lower:\n                suggestions.extend([\n                    \"What are the provisions for income tax computation?\",\n                    \"Explain deferred tax assets and liabilities\",\n                    \"How to calculate tax on different types of income?\"\n                ])\n            \n            elif 'audit' in question_lower:\n                suggestions.extend([\n                    \"What are the key auditing standards?\",\n                    \"Explain the audit process and procedures\",\n                    \"What are the types of audit opinions?\"\n                ])\n            \n            # Level-specific suggestions\n            if level == \"Foundation\":\n                suggestions.extend([\n                    \"What are the fundamental accounting principles?\",\n                    \"Explain the accounting equation and its applications\"\n                ])\n            elif level == \"Intermediate\":\n                suggestions.extend([\n                    \"How to apply Ind AS in practical scenarios?\",\n                    \"Explain advanced accounting treatments\"\n                ])\n            elif level == \"Final\":\n                suggestions.extend([\n                    \"What are the latest updates in accounting standards?\",\n                    \"Explain complex financial reporting requirements\"\n                ])\n            \n            # Return unique suggestions, limited to 5\n            return list(set(suggestions))[:5]\n            \n        except Exception as e:\n            logger.error(f\"Failed to generate suggestions: {e}\")\n            return []\n    \n    def get_progressive_learning_path(self, topic: str, current_level: str) -> Dict[str, Any]:\n        \"\"\"Generate a progressive learning path for a topic\"\"\"\n        try:\n            learning_path = {\n                'current_level': current_level,\n                'topic': topic,\n                'prerequisites': [],\n                'current_concepts': [],\n                'next_steps': [],\n                'related_topics': []\n            }\n            \n            # This would be enhanced with actual curriculum mapping\n            # For now, providing a basic structure\n            \n            if current_level == \"Foundation\":\n                learning_path['prerequisites'] = [\"Basic accounting concepts\", \"Double entry system\"]\n                learning_path['next_steps'] = [\"Advanced accounting\", \"Financial statement analysis\"]\n            \n            elif current_level == \"Intermediate\":\n                learning_path['prerequisites'] = [\"Foundation level knowledge\", \"Basic standards\"]\n                learning_path['next_steps'] = [\"Advanced standards\", \"Practical applications\"]\n            \n            elif current_level == \"Final\":\n                learning_path['prerequisites'] = [\"Intermediate level mastery\", \"Practical exposure\"]\n                learning_path['next_steps'] = [\"Professional application\", \"Industry specialization\"]\n            \n            return learning_path\n            \n        except Exception as e:\n            logger.error(f\"Failed to generate learning path: {e}\")\n            return {'error': str(e)}\n","size_bytes":18277},"replit.md":{"content":"# Overview\n\nThis is a CA (Chartered Accountancy) RAG (Retrieval-Augmented Generation) Assistant built with Streamlit. The application allows users to upload CA study materials in PDF format, processes them to extract text and tables, stores the content in a vector database, and provides an intelligent Q&A interface. The system is specifically designed for CA course materials across Foundation, Intermediate, and Final levels, with structured paper and module organization.\n\n# User Preferences\n\nPreferred communication style: Simple, everyday language.\n\n# System Architecture\n\n## Frontend Architecture\n- **Framework**: Streamlit web application with session state management\n- **User Interface**: Single-page application with sidebar navigation and file upload capabilities\n- **State Management**: Streamlit session state for component initialization, processing status, and chat history\n- **File Handling**: Temporary file processing with automatic cleanup\n\n## Backend Architecture\n- **Modular Design**: Separated concerns across multiple specialized modules:\n  - PDF processing for text and table extraction\n  - Vector database operations for similarity search\n  - Embedding generation and management\n  - RAG pipeline for question answering\n  - Table-specific processing for financial data\n- **Processing Pipeline**: Multi-stage PDF processing using PyMuPDF, pdfplumber, and Camelot for comprehensive content extraction\n- **RAG Implementation**: Context-aware retrieval with filtering by CA levels, papers, modules, and chapters\n\n## Data Storage Architecture\n- **Vector Database**: PostgreSQL with pgvector extension for storing document embeddings and metadata\n- **Database Schema**: Separate tables for documents (text chunks) and tables (structured data) with rich metadata\n- **File Storage**: Appwrite cloud storage for PDF file management with automatic database setup\n- **Metadata Management**: Comprehensive tracking of file processing status, CA course structure mapping, and content relationships\n\n## Authentication and Authorization\n- **Service-based Authentication**: API key-based authentication for Azure OpenAI and Appwrite services\n- **No User Authentication**: Simple single-user application without user management\n\n## AI and ML Components\n- **Embedding Model**: Azure OpenAI text-embedding-ada-002 for semantic search\n- **Language Model**: Azure OpenAI GPT-4 for question answering\n- **Batch Processing**: Optimized embedding generation with rate limiting and batch processing\n- **Table-aware RAG**: Specialized processing for financial tables and numerical data common in CA materials\n\n# External Dependencies\n\n## AI Services\n- **Azure OpenAI**: Primary AI service for embeddings (text-embedding-ada-002) and language model (GPT-4)\n- **Configuration**: Endpoint, API key, and deployment names configurable via environment variables\n\n## Database Services\n- **PostgreSQL**: Primary database with pgvector extension for vector similarity search\n- **Connection**: Full PostgreSQL connection parameters (host, port, database, user, password)\n\n## Cloud Storage\n- **Appwrite**: Cloud storage service for PDF file management\n- **Configuration**: Endpoint, project ID, API key, and bucket ID for file storage\n- **Auto-setup**: Automatic database and collection creation for metadata management\n\n## PDF Processing Libraries\n- **PyMuPDF (fitz)**: Primary PDF text extraction\n- **pdfplumber**: Enhanced table detection and extraction\n- **Camelot**: Advanced table extraction for complex layouts\n- **tabula-py**: Alternative table extraction method\n- **pytesseract**: OCR capabilities for image-based content\n\n## Data Processing\n- **pandas**: Data manipulation and table processing\n- **numpy**: Numerical operations for embeddings and vector calculations\n- **OpenCV**: Image processing for PDF content analysis\n\n## Web Framework\n- **Streamlit**: Complete web application framework with built-in state management and UI components\n\n## Utility Libraries\n- **psycopg2**: PostgreSQL database adapter\n- **python-multipart**: File upload handling\n- **Pillow**: Image processing support","size_bytes":4089},"table_processor.py":{"content":"import pandas as pd\nimport numpy as np\nfrom typing import List, Dict, Any, Tuple\nimport re\nimport logging\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nclass TableProcessor:\n    def __init__(self):\n        self.financial_keywords = [\n            'amount', 'balance', 'debit', 'credit', 'total', 'subtotal',\n            'assets', 'liabilities', 'equity', 'revenue', 'expense',\n            'profit', 'loss', 'cash', 'investment', 'depreciation',\n            'interest', 'dividend', 'tax', 'provision', 'reserve'\n        ]\n        \n        self.table_types = {\n            'balance_sheet': ['assets', 'liabilities', 'equity', 'balance'],\n            'income_statement': ['revenue', 'expense', 'profit', 'loss', 'income'],\n            'cash_flow': ['cash', 'operating', 'investing', 'financing', 'flow'],\n            'ratio_analysis': ['ratio', 'current', 'quick', 'debt', 'return'],\n            'schedule': ['schedule', 'breakdown', 'details', 'analysis'],\n            'general': ['table', 'data', 'information']\n        }\n    \n    def process_table_for_embedding(self, table_data: Dict[str, Any]) -> str:\n        \"\"\"\n        Convert table data to text format optimized for embeddings\n        Preserves numerical relationships and structure\n        \"\"\"\n        try:\n            # Extract table information\n            data = table_data.get('data', [])\n            columns = table_data.get('columns', [])\n            context_before = table_data.get('context_before', '')\n            context_after = table_data.get('context_after', '')\n            \n            if not data or not columns:\n                return f\"Table from page {table_data.get('page_number', 'unknown')}: No data available\"\n            \n            # Create DataFrame for processing\n            df = pd.DataFrame(data)\n            \n            # Identify table type\n            table_type = self._identify_table_type(table_data)\n            \n            # Build text representation\n            text_parts = []\n            \n            # Add context\n            if context_before:\n                text_parts.append(f\"Context before table: {context_before}\")\n            \n            # Add table metadata\n            text_parts.append(f\"Table Type: {table_type}\")\n            text_parts.append(f\"Table from page {table_data.get('page_number', 'unknown')}\")\n            text_parts.append(f\"Dimensions: {len(data)} rows Ã— {len(columns)} columns\")\n            \n            # Add column headers with emphasis\n            text_parts.append(f\"Column Headers: {', '.join(columns)}\")\n            \n            # Process table content\n            processed_content = self._process_table_content(df, table_type)\n            text_parts.append(processed_content)\n            \n            # Add numerical summaries if applicable\n            numerical_summary = self._create_numerical_summary(df)\n            if numerical_summary:\n                text_parts.append(f\"Numerical Summary: {numerical_summary}\")\n            \n            # Add financial insights if it's a financial table\n            if table_type in ['balance_sheet', 'income_statement', 'cash_flow', 'ratio_analysis']:\n                financial_insights = self._extract_financial_insights(df, table_type)\n                if financial_insights:\n                    text_parts.append(f\"Financial Insights: {financial_insights}\")\n            \n            # Add context after\n            if context_after:\n                text_parts.append(f\"Context after table: {context_after}\")\n            \n            return ' | '.join(text_parts)\n            \n        except Exception as e:\n            logger.error(f\"Failed to process table for embedding: {e}\")\n            return f\"Table processing error from page {table_data.get('page_number', 'unknown')}\"\n    \n    def _identify_table_type(self, table_data: Dict[str, Any]) -> str:\n        \"\"\"Identify the type of table based on content and context\"\"\"\n        try:\n            # Combine all text sources for analysis\n            text_to_analyze = \"\"\n            \n            if 'columns' in table_data:\n                text_to_analyze += \" \".join(table_data['columns'])\n            \n            if 'context_before' in table_data:\n                text_to_analyze += \" \" + table_data.get('context_before', '')\n            \n            if 'context_after' in table_data:\n                text_to_analyze += \" \" + table_data.get('context_after', '')\n            \n            if 'data' in table_data and table_data['data']:\n                # Add first row content\n                first_row = table_data['data'][0]\n                if isinstance(first_row, dict):\n                    text_to_analyze += \" \" + \" \".join(str(v) for v in first_row.values())\n            \n            text_to_analyze = text_to_analyze.lower()\n            \n            # Score each table type\n            type_scores = {}\n            for table_type, keywords in self.table_types.items():\n                score = sum(1 for keyword in keywords if keyword in text_to_analyze)\n                type_scores[table_type] = score\n            \n            # Return the type with highest score\n            if type_scores:\n                best_type = max(type_scores.keys(), key=lambda k: type_scores[k])\n                if type_scores[best_type] > 0:\n                    return best_type\n            \n            return 'general'\n            \n        except Exception as e:\n            logger.warning(f\"Failed to identify table type: {e}\")\n            return 'general'\n    \n    def _process_table_content(self, df: pd.DataFrame, table_type: str) -> str:\n        \"\"\"Process table content based on its type\"\"\"\n        try:\n            content_parts = []\n            \n            # Add row-by-row content with enhanced formatting for financial tables\n            for idx, row in df.iterrows():\n                row_text = f\"Row {int(idx) + 1}:\"\n                \n                for col_name, value in row.items():\n                    if pd.notna(value) and str(value).strip():\n                        # Special formatting for financial values\n                        if self._is_financial_value(str(value)):\n                            formatted_value = self._format_financial_value(str(value))\n                            row_text += f\" {col_name}: {formatted_value},\"\n                        else:\n                            row_text += f\" {col_name}: {str(value).strip()},\"\n                \n                content_parts.append(row_text.rstrip(','))\n            \n            # Add totals and key figures if identifiable\n            totals_info = self._identify_totals_and_keys(df)\n            if totals_info:\n                content_parts.append(f\"Key Figures: {totals_info}\")\n            \n            return ' | '.join(content_parts)\n            \n        except Exception as e:\n            logger.warning(f\"Failed to process table content: {e}\")\n            return str(df.to_string())\n    \n    def _is_financial_value(self, value: str) -> bool:\n        \"\"\"Check if a value appears to be a financial amount\"\"\"\n        # Remove common formatting\n        cleaned = re.sub(r'[â‚¹$,\\s]', '', value)\n        \n        # Check if it's a number (possibly with decimal)\n        try:\n            float(cleaned)\n            return True\n        except ValueError:\n            pass\n        \n        # Check for percentage\n        if '%' in value:\n            return True\n        \n        # Check for negative values in brackets\n        if re.match(r'\\(.*\\)', value.strip()):\n            return True\n        \n        return False\n    \n    def _format_financial_value(self, value: str) -> str:\n        \"\"\"Format financial values for better understanding\"\"\"\n        # Preserve original formatting but add context\n        if 'â‚¹' in value or 'Rs' in value.upper():\n            return f\"{value} (Indian Rupees)\"\n        elif '$' in value:\n            return f\"{value} (Dollars)\"\n        elif '%' in value:\n            return f\"{value} (Percentage)\"\n        elif re.match(r'\\(.*\\)', value.strip()):\n            return f\"{value} (Negative amount in brackets)\"\n        \n        return value\n    \n    def _create_numerical_summary(self, df: pd.DataFrame) -> str:\n        \"\"\"Create a summary of numerical data in the table\"\"\"\n        try:\n            numerical_cols = []\n            \n            for col in df.columns:\n                # Try to convert column to numeric\n                try:\n                    numeric_data = pd.to_numeric(df[col], errors='coerce')\n                    non_null_count = numeric_data.count()\n                    \n                    if non_null_count > 0:  # Column has some numeric data\n                        total = numeric_data.sum()\n                        avg = numeric_data.mean()\n                except Exception:\n                    continue\n                    \n                    numerical_cols.append(f\"{col}: Total={total:.2f}, Average={avg:.2f}\")\n            \n            return ', '.join(numerical_cols) if numerical_cols else \"\"\n            \n        except Exception as e:\n            logger.warning(f\"Failed to create numerical summary: {e}\")\n            return \"\"\n    \n    def _identify_totals_and_keys(self, df: pd.DataFrame) -> str:\n        \"\"\"Identify total rows and key figures\"\"\"\n        try:\n            key_info = []\n            \n            # Look for rows that might contain totals\n            for idx, row in df.iterrows():\n                row_text = ' '.join(str(v).lower() for v in row.values if pd.notna(v))\n                \n                if any(keyword in row_text for keyword in ['total', 'subtotal', 'grand total', 'net']):\n                    key_info.append(f\"Total row {int(idx) + 1}: {dict(row)}\")\n            \n            # Look for the last row (often contains totals)\n            if len(df) > 1:\n                last_row = df.iloc[-1]\n                if any(self._is_financial_value(str(v)) for v in last_row.values if pd.notna(v)):\n                    key_info.append(f\"Last row (possibly total): {dict(last_row)}\")\n            \n            return ' | '.join(key_info) if key_info else \"\"\n            \n        except Exception as e:\n            logger.warning(f\"Failed to identify totals and keys: {e}\")\n            return \"\"\n    \n    def _extract_financial_insights(self, df: pd.DataFrame, table_type: str) -> str:\n        \"\"\"Extract financial insights based on table type\"\"\"\n        try:\n            insights = []\n            \n            if table_type == 'balance_sheet':\n                # Look for basic balance sheet structure\n                for col in df.columns:\n                    col_lower = col.lower()\n                    if 'asset' in col_lower:\n                        insights.append(f\"Assets column: {col}\")\n                    elif 'liabilit' in col_lower:\n                        insights.append(f\"Liabilities column: {col}\")\n                    elif 'equit' in col_lower:\n                        insights.append(f\"Equity column: {col}\")\n            \n            elif table_type == 'income_statement':\n                # Look for P&L structure\n                for col in df.columns:\n                    col_lower = col.lower()\n                    if any(word in col_lower for word in ['revenue', 'income', 'sales']):\n                        insights.append(f\"Revenue/Income column: {col}\")\n                    elif any(word in col_lower for word in ['expense', 'cost', 'expenditure']):\n                        insights.append(f\"Expense column: {col}\")\n            \n            elif table_type == 'cash_flow':\n                # Look for cash flow components\n                for col in df.columns:\n                    col_lower = col.lower()\n                    if 'operating' in col_lower:\n                        insights.append(f\"Operating activities: {col}\")\n                    elif 'investing' in col_lower:\n                        insights.append(f\"Investing activities: {col}\")\n                    elif 'financing' in col_lower:\n                        insights.append(f\"Financing activities: {col}\")\n            \n            return ', '.join(insights) if insights else \"\"\n            \n        except Exception as e:\n            logger.warning(f\"Failed to extract financial insights: {e}\")\n            return \"\"\n    \n    def create_table_embedding_text(self, table_data: Dict[str, Any], \n                                  metadata: Dict[str, str]) -> str:\n        \"\"\"\n        Create comprehensive text for table embedding that includes metadata context\n        \"\"\"\n        try:\n            # Start with metadata context\n            metadata_parts = []\n            \n            if metadata.get('level'):\n                metadata_parts.append(f\"CA Level: {metadata['level']}\")\n            if metadata.get('paper'):\n                metadata_parts.append(f\"Paper: {metadata['paper']}\")\n            if metadata.get('module'):\n                metadata_parts.append(f\"Module: {metadata['module']}\")\n            if metadata.get('chapter'):\n                metadata_parts.append(f\"Chapter: {metadata['chapter']}\")\n            if metadata.get('unit'):\n                metadata_parts.append(f\"Unit: {metadata['unit']}\")\n            \n            metadata_context = ' | '.join(metadata_parts)\n            \n            # Get table content\n            table_content = self.process_table_for_embedding(table_data)\n            \n            # Combine metadata and content\n            full_text = f\"Metadata: {metadata_context} | Table Content: {table_content}\"\n            \n            return full_text\n            \n        except Exception as e:\n            logger.error(f\"Failed to create table embedding text: {e}\")\n            return f\"Table from {metadata.get('level', 'unknown')} level\"\n    \n    def chunk_table_aware_text(self, text: str, tables_info: List[Dict], \n                              chunk_size: int = 1000, overlap: int = 200) -> List[Dict]:\n        \"\"\"\n        Chunk text while preserving table context and references\n        \"\"\"\n        try:\n            chunks = []\n            \n            # Split text into paragraphs first\n            paragraphs = text.split('\\n\\n')\n            \n            current_chunk = \"\"\n            current_chunk_tables = []\n            chunk_index = 0\n            \n            for para in paragraphs:\n                para = para.strip()\n                if not para:\n                    continue\n                \n                # Check if adding this paragraph exceeds chunk size\n                if len(current_chunk) + len(para) + 2 > chunk_size and current_chunk:\n                    # Save current chunk\n                    chunks.append({\n                        'content': current_chunk.strip(),\n                        'chunk_index': chunk_index,\n                        'table_references': current_chunk_tables.copy(),\n                        'has_tables': bool(current_chunk_tables)\n                    })\n                    \n                    chunk_index += 1\n                    \n                    # Start new chunk with overlap\n                    if overlap > 0 and len(current_chunk) > overlap:\n                        current_chunk = current_chunk[-overlap:] + \"\\n\\n\" + para\n                    else:\n                        current_chunk = para\n                    current_chunk_tables = []\n                else:\n                    # Add paragraph to current chunk\n                    if current_chunk:\n                        current_chunk += \"\\n\\n\" + para\n                    else:\n                        current_chunk = para\n                \n                # Check if this paragraph references any tables\n                for table_info in tables_info:\n                    if self._paragraph_references_table(para, table_info):\n                        if table_info not in current_chunk_tables:\n                            current_chunk_tables.append(table_info)\n            \n            # Add final chunk if any content remains\n            if current_chunk.strip():\n                chunks.append({\n                    'content': current_chunk.strip(),\n                    'chunk_index': chunk_index,\n                    'table_references': current_chunk_tables,\n                    'has_tables': bool(current_chunk_tables)\n                })\n            \n            logger.info(f\"Created {len(chunks)} table-aware text chunks\")\n            return chunks\n            \n        except Exception as e:\n            logger.error(f\"Failed to create table-aware chunks: {e}\")\n            return [{'content': text, 'chunk_index': 0, 'table_references': [], 'has_tables': False}]\n    \n    def _paragraph_references_table(self, paragraph: str, table_info: Dict) -> bool:\n        \"\"\"Check if a paragraph might reference a specific table\"\"\"\n        try:\n            para_lower = paragraph.lower()\n            \n            # Check for explicit table references\n            table_keywords = ['table', 'schedule', 'statement', 'above', 'below', 'following']\n            \n            if any(keyword in para_lower for keyword in table_keywords):\n                # If table has specific identifiers, check for those\n                if 'extraction_method' in table_info:\n                    method = table_info['extraction_method'].lower()\n                    if any(word in para_lower for word in method.split('-')):\n                        return True\n                \n                # Check for financial keywords if it's a financial table\n                if table_info.get('rows', 0) > 1:\n                    financial_refs = sum(1 for keyword in self.financial_keywords \n                                       if keyword in para_lower)\n                    if financial_refs >= 2:  # Multiple financial terms suggest table reference\n                        return True\n            \n            return False\n            \n        except Exception as e:\n            logger.warning(f\"Failed to check table reference: {e}\")\n            return False\n","size_bytes":17909},"utils.py":{"content":"import os\nimport hashlib\nimport tempfile\nimport shutil\nfrom typing import Dict, Any, List, Optional\nimport logging\nfrom datetime import datetime\nimport re\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nclass FileUtils:\n    @staticmethod\n    def generate_file_id(file_path: str) -> str:\n        \"\"\"Generate a unique file ID based on file content\"\"\"\n        try:\n            with open(file_path, 'rb') as f:\n                file_hash = hashlib.md5(f.read()).hexdigest()\n            \n            file_name = os.path.basename(file_path)\n            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n            \n            return f\"{file_name}_{timestamp}_{file_hash[:8]}\"\n            \n        except Exception as e:\n            logger.error(f\"Failed to generate file ID: {e}\")\n            return f\"file_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n    \n    @staticmethod\n    def create_temp_file(content: bytes, suffix: str = \".pdf\") -> str:\n        \"\"\"Create a temporary file with given content\"\"\"\n        try:\n            temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=suffix)\n            temp_file.write(content)\n            temp_file.close()\n            return temp_file.name\n            \n        except Exception as e:\n            logger.error(f\"Failed to create temp file: {e}\")\n            raise\n    \n    @staticmethod\n    def cleanup_temp_file(file_path: str):\n        \"\"\"Clean up temporary file\"\"\"\n        try:\n            if os.path.exists(file_path):\n                os.unlink(file_path)\n                logger.info(f\"Cleaned up temp file: {file_path}\")\n        except Exception as e:\n            logger.warning(f\"Failed to cleanup temp file: {e}\")\n    \n    @staticmethod\n    def validate_pdf_file(file_path: str) -> bool:\n        \"\"\"Validate if file is a valid PDF\"\"\"\n        try:\n            with open(file_path, 'rb') as f:\n                header = f.read(8)\n                return header.startswith(b'%PDF-')\n        except Exception as e:\n            logger.error(f\"PDF validation failed: {e}\")\n            return False\n    \n    @staticmethod\n    def get_file_size(file_path: str) -> int:\n        \"\"\"Get file size in bytes\"\"\"\n        try:\n            return os.path.getsize(file_path)\n        except Exception as e:\n            logger.error(f\"Failed to get file size: {e}\")\n            return 0\n\nclass TextUtils:\n    @staticmethod\n    def clean_text(text: str) -> str:\n        \"\"\"Clean and normalize text\"\"\"\n        try:\n            # Remove excessive whitespace\n            text = re.sub(r'\\s+', ' ', text)\n            \n            # Remove special characters but keep basic punctuation\n            text = re.sub(r'[^\\w\\s\\.\\,\\?\\!\\;\\:\\-\\(\\)\\[\\]\\/\\%\\â‚¹\\$]', '', text)\n            \n            # Remove extra spaces\n            text = text.strip()\n            \n            return text\n            \n        except Exception as e:\n            logger.error(f\"Text cleaning failed: {e}\")\n            return text\n    \n    @staticmethod\n    def extract_financial_figures(text: str) -> List[Dict[str, str]]:\n        \"\"\"Extract financial figures from text\"\"\"\n        try:\n            figures = []\n            \n            # Pattern for Indian currency\n            inr_pattern = r'â‚¹\\s*(\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?)'\n            inr_matches = re.finditer(inr_pattern, text)\n            \n            for match in inr_matches:\n                figures.append({\n                    'amount': match.group(0),\n                    'value': match.group(1),\n                    'currency': 'INR',\n                    'position': match.start()\n                })\n            \n            # Pattern for percentages\n            percent_pattern = r'(\\d+(?:\\.\\d+)?)\\s*%'\n            percent_matches = re.finditer(percent_pattern, text)\n            \n            for match in percent_matches:\n                figures.append({\n                    'amount': match.group(0),\n                    'value': match.group(1),\n                    'currency': 'percentage',\n                    'position': match.start()\n                })\n            \n            return figures\n            \n        except Exception as e:\n            logger.error(f\"Financial figure extraction failed: {e}\")\n            return []\n    \n    @staticmethod\n    def extract_references(text: str) -> List[Dict[str, str]]:\n        \"\"\"Extract references to standards, sections, etc.\"\"\"\n        try:\n            references = []\n            \n            # Ind AS references\n            indas_pattern = r'Ind\\s*AS\\s*(\\d+)'\n            indas_matches = re.finditer(indas_pattern, text, re.IGNORECASE)\n            \n            for match in indas_matches:\n                references.append({\n                    'type': 'Ind AS',\n                    'reference': match.group(0),\n                    'number': match.group(1),\n                    'position': match.start()\n                })\n            \n            # Section references\n            section_pattern = r'Section\\s*(\\d+(?:\\([a-zA-Z0-9]+\\))?)'\n            section_matches = re.finditer(section_pattern, text, re.IGNORECASE)\n            \n            for match in section_matches:\n                references.append({\n                    'type': 'Section',\n                    'reference': match.group(0),\n                    'number': match.group(1),\n                    'position': match.start()\n                })\n            \n            return references\n            \n        except Exception as e:\n            logger.error(f\"Reference extraction failed: {e}\")\n            return []\n\nclass ValidationUtils:\n    @staticmethod\n    def validate_metadata(metadata: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Validate and clean metadata\"\"\"\n        try:\n            validated = {}\n            \n            # Required fields\n            required_fields = ['level', 'paper', 'file_name']\n            for field in required_fields:\n                if field in metadata and metadata[field]:\n                    validated[field] = str(metadata[field]).strip()\n                else:\n                    raise ValueError(f\"Missing required field: {field}\")\n            \n            # Optional fields\n            optional_fields = ['module', 'chapter', 'unit']\n            for field in optional_fields:\n                if field in metadata and metadata[field]:\n                    validated[field] = str(metadata[field]).strip()\n                else:\n                    validated[field] = None\n            \n            # Numeric fields\n            if 'total_pages' in metadata:\n                try:\n                    validated['total_pages'] = int(metadata['total_pages'])\n                except (ValueError, TypeError):\n                    validated['total_pages'] = 0\n            \n            return validated\n            \n        except Exception as e:\n            logger.error(f\"Metadata validation failed: {e}\")\n            raise\n    \n    @staticmethod\n    def validate_ca_level(level: str) -> bool:\n        \"\"\"Validate CA level\"\"\"\n        valid_levels = ['Foundation', 'Intermediate', 'Final']\n        return level in valid_levels\n    \n    @staticmethod\n    def validate_question(question: str) -> bool:\n        \"\"\"Validate user question\"\"\"\n        if not question or not question.strip():\n            return False\n        \n        # Minimum length check\n        if len(question.strip()) < 5:\n            return False\n        \n        # Maximum length check\n        if len(question.strip()) > 1000:\n            return False\n        \n        return True\n\nclass ProgressTracker:\n    def __init__(self, total_steps: int):\n        self.total_steps = total_steps\n        self.current_step = 0\n        self.step_descriptions = {}\n    \n    def update(self, step: int, description: str = \"\"):\n        \"\"\"Update progress\"\"\"\n        self.current_step = step\n        if description:\n            self.step_descriptions[step] = description\n        \n        logger.info(f\"Progress: {step}/{self.total_steps} - {description}\")\n    \n    def get_progress_percentage(self) -> float:\n        \"\"\"Get progress as percentage\"\"\"\n        if self.total_steps == 0:\n            return 100.0\n        \n        return (self.current_step / self.total_steps) * 100\n    \n    def is_complete(self) -> bool:\n        \"\"\"Check if process is complete\"\"\"\n        return self.current_step >= self.total_steps\n\nclass ResponseFormatter:\n    @staticmethod\n    def format_answer_response(answer_data: Dict[str, Any]) -> str:\n        \"\"\"Format answer response for display\"\"\"\n        try:\n            formatted_parts = []\n            \n            # Main answer\n            formatted_parts.append(f\"**Answer:**\\n{answer_data['answer']}\")\n            \n            # Confidence\n            if answer_data.get('confidence'):\n                confidence_percent = answer_data['confidence'] * 100\n                formatted_parts.append(f\"**Confidence:** {confidence_percent:.1f}%\")\n            \n            # Sources\n            if answer_data.get('sources'):\n                sources = answer_data['sources']\n                \n                if sources.get('documents'):\n                    formatted_parts.append(\"**Document Sources:**\")\n                    for i, doc in enumerate(sources['documents'][:3]):\n                        formatted_parts.append(f\"{i+1}. {doc['file_name']} (Level: {doc['level']}, Paper: {doc['paper']})\")\n                \n                if sources.get('tables'):\n                    formatted_parts.append(\"**Table Sources:**\")\n                    for i, table in enumerate(sources['tables'][:2]):\n                        formatted_parts.append(f\"{i+1}. {table['file_name']}, Page {table['page_number']} ({table['rows']}x{table['cols']} table)\")\n            \n            return \"\\n\\n\".join(formatted_parts)\n            \n        except Exception as e:\n            logger.error(f\"Response formatting failed: {e}\")\n            return answer_data.get('answer', 'Error formatting response')\n    \n    @staticmethod\n    def format_processing_status(status_data: Dict[str, Any]) -> str:\n        \"\"\"Format processing status for display\"\"\"\n        try:\n            status_parts = []\n            \n            status_parts.append(f\"**File:** {status_data.get('file_name', 'Unknown')}\")\n            status_parts.append(f\"**Status:** {status_data.get('status', 'Unknown')}\")\n            \n            if status_data.get('progress'):\n                status_parts.append(f\"**Progress:** {status_data['progress']:.1f}%\")\n            \n            if status_data.get('current_step'):\n                status_parts.append(f\"**Current Step:** {status_data['current_step']}\")\n            \n            if status_data.get('error'):\n                status_parts.append(f\"**Error:** {status_data['error']}\")\n            \n            return \"\\n\".join(status_parts)\n            \n        except Exception as e:\n            logger.error(f\"Status formatting failed: {e}\")\n            return \"Error formatting status\"\n","size_bytes":10921}},"version":1}